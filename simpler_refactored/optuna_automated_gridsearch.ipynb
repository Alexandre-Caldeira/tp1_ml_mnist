{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7   0  84 185 159 151  60  36 222 254 241 198 170  52  67 114  72 163\n",
      " 227 225 250 229 140  17  66  14  59  21 236 106  83 253 209  18  22 233\n",
      " 255 129 238  44 249  62 133 187   5   9 205 248  58 126 182  75 251 240\n",
      "  57  19 221 166   3 203 219  35  38  77  31 224 115   1  61 242 121  40\n",
      " 207]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  7  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  2  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  784  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data_tp1.csv',header=None)\n",
    "data = data.rename(columns={0:'y'})\n",
    "print(data.iloc[0,:].unique())\n",
    "\n",
    "imsize = round(np.sqrt(784)+1)\n",
    "linha_y = 4\n",
    "img = np.reshape(data.iloc[linha_y,1:].values, (imsize-1,imsize-1))\n",
    "plt.imshow(255-img,cmap='gray')\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def data and model shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 784)\n",
      "(3350,)\n",
      "(784,)\n",
      "7\n",
      "Shape, type: X: torch.Size([25, 784]) torch.float32\n",
      "Shape, type: y: torch.Size([25]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data.y.values\n",
    "X = data.drop(columns='y').values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "idx = 0\n",
    "print((X_train[idx,:]).shape)\n",
    "print(y_train[idx])\n",
    "(y_train[idx]).shape \n",
    "\n",
    "# Pytorch exige que seja utilizado um dataset por algum motivo aparentemente\n",
    "class custom_mnist_dataset():\n",
    "    def __init__(self, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # RestriÃ§Ãµes de uso do pytorch: (leia os docs...)\n",
    "        # inputs tem que ser float para multiplicar pelos pesos, \n",
    "        # outputs tem que ser longint para calcular crossentropy \n",
    "        return torch.tensor(self.X[idx,:], dtype=torch.float), self.y[idx]\n",
    "\n",
    "training_data = custom_mnist_dataset(X = X_train, y = y_train)\n",
    "test_data = custom_mnist_dataset(X = X_test, y = y_test)\n",
    "\n",
    "# batch_size de exemplo para teste\n",
    "batch_size = 25\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape, type: X: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape, type: y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (entrada): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (oculta): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (saida): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "NeuralNetwork with  ...\n",
    "\"\"\"\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.entrada = nn.Linear(input_size, hidden_dim)\n",
    "        self.oculta = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.saida = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x1 = self.entrada(input)\n",
    "        x2 = F.sigmoid(self.oculta(x1))\n",
    "        x3 = self.saida(x2)\n",
    "\n",
    "        return x3\n",
    "    \n",
    "# hidden dim = 25,50,100\n",
    "print(NeuralNetwork(input_size = X_train.shape[1], hidden_dim= 25, output_size=10).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def train, test and eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/shrutimechlearn/pytorch-custom-model-step-by-step\n",
    "\n",
    "def train_step(model, loss_func, optimizer, dataloader):\n",
    "    \n",
    "    # to capture loss\n",
    "    train_loss = 0 \n",
    "\n",
    "    # to get the model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        # sending data to the device where rest of the artifacts are\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # forward pass/model prediction with the given input\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # loss calculation by comparison between predicted and ground truth values\n",
    "        loss = loss_func(y_pred, y_batch)\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "        # setting previously collected gradient values in the optimizer to zero so it translates only current gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate the gradients for this iteration (independent gradients because previous values have been reset to 0)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights and biases based on the calculated gradients ~(wi = wi + delta_wi)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, loss_func, test_dataloader):\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for batch, (x_batch, y_batch) in enumerate(test_dataloader):\n",
    "            \n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            loss = loss_func(y_pred, y_batch)\n",
    "            test_loss+= loss.item()\n",
    "\n",
    "    test_loss = test_loss/len(test_dataloader)   \n",
    "\n",
    "    return test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch import optim\n",
    "\n",
    "def eval_step_with_mlflowlogging(model,test_dataloader):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_preds = []\n",
    "        total_labels = []\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(total_labels, total_preds)\n",
    "    precision = precision_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    recall = recall_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def train_with_mlflowlogging(model, loss_func, optimizer, train_dataloader, test_dataloader, n_epochs, i,lr,hds,bs):\n",
    "    with mlflow.start_run(run_name=f\"Test #{i} - lr({lr}) hds({hds}) bs({bs})\", nested = True):  # Name each run based on the learning rate\n",
    "        mlflow.log_param(\"batch_size\", bs)\n",
    "        mlflow.log_param(\"hidden_dim\", hds)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        \n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "    \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            tr_loss = train_step(model, loss_func, optimizer, train_dataloader)\n",
    "            train_loss.append(tr_loss)\n",
    "        \n",
    "            ts_loss = test_step(model, loss_func, test_dataloader)\n",
    "            test_loss.append(ts_loss)    \n",
    "\n",
    "            accuracy, precision, recall, f1 = eval_step_with_mlflowlogging(model, test_dataloader)\n",
    "            \n",
    "            mlflow.log_metric(\"loss\", tr_loss, step = epoch)\n",
    "            mlflow.log_metric(\"val_loss\", ts_loss, step = epoch)\n",
    "            mlflow.log_metric(\"diff_loss_tr_ts\", tr_loss-ts_loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"loss\", tr_loss, step = epoch)\n",
    "            mlflow.log_metric(\"val_loss\", ts_loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"accuracy\", accuracy, step = epoch)\n",
    "            mlflow.log_metric(\"precision\", precision, step = epoch)\n",
    "            mlflow.log_metric(\"recall\", recall, step = epoch)\n",
    "            mlflow.log_metric(\"f1\", f1, step = epoch)   \n",
    "\n",
    "    return train_loss, test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def automated trials and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import torch.optim as optim\n",
    "\n",
    "\n",
    "# # Assuming the rest of your imports and setup code remains the same\n",
    "\n",
    "# def objective(trial, lr, hds, bs):\n",
    "#     # Suggest regularization parameter using the trial object\n",
    "#     weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n",
    "    \n",
    "#     # Initialize the model with fixed hyperparameters and suggested regularization\n",
    "#     model = NeuralNetwork(input_size=X_train.shape[1], hidden_dim=hds, output_size=10).to(device)\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "#     # Training and evaluation steps remain the same, just ensure they use the model, loss_func, and optimizer initialized above\n",
    "#     # Note: You might need to adjust the train_with_mlflowlogging function to remove mlflow logging since we're focusing on Optuna integration now\n",
    "#     loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     # Example of how you might structure the training and evaluation inside the objective function\n",
    "#     for epoch in range(5):  # Number of epochs\n",
    "#         train_loss = train_step(model, loss_func, optimizer, train_dataloader)\n",
    "#         test_loss = test_step(model, loss_func, test_dataloader)\n",
    "#         # Evaluate other metrics as needed\n",
    "\n",
    "#     # Return a value that Optuna will try to minimize/maximize. For example, you could return the negative mean test loss\n",
    "#     return test_loss\n",
    "\n",
    "# # Fixed hyperparameters\n",
    "# fixed_hyperparams = {\n",
    "#     'learning_rates': [0.5, 1, 10],\n",
    "#     'hidden_dim_sizes': [25, 50, 100],\n",
    "#     'batch_sizes': [1, 10, 50, len(training_data)],\n",
    "# }\n",
    "\n",
    "\n",
    "# # Iterate over fixed hyperparameters\n",
    "# best_results = {}\n",
    "# for lr in fixed_hyperparams['learning_rates']:\n",
    "#     for hds in fixed_hyperparams['hidden_dim_sizes']:\n",
    "#         for bs in fixed_hyperparams['batch_sizes']:\n",
    "#             # Create an Optuna study for each combination\n",
    "#             study = optuna.create_study(direction='minimize')\n",
    "#             study.optimize(lambda t: objective(t, lr, hds, bs), n_trials=10)  # Adjust n_trials as needed\n",
    "            \n",
    "#             # Record the best trial\n",
    "#             best_trial = study.best_trial\n",
    "#             best_weight_decay = best_trial.params['weight_decay']\n",
    "#             best_test_loss = best_trial.value\n",
    "            \n",
    "#             # Record best results\n",
    "#             best_results[(lr, hds, bs)] = {\n",
    "#                 'weight_decay': best_weight_decay,\n",
    "#                 'test_loss': best_test_loss,\n",
    "#             }\n",
    "\n",
    "# # Print the best results\n",
    "# for (lr, hds, bs), result in best_results.items():\n",
    "#     print(f\"Learning Rate: {lr}, Hidden Dimension Size: {hds}, Batch Size: {bs}\")\n",
    "#     print(f\"Best Weight Decay: {result['weight_decay']}, Test Loss: {result['test_loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/14 17:14:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2024/06/14 17:14:00 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240614T171400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/14 17:14:02 INFO mlflow.tracking.fluent: Experiment with name 'TP1ML - 20240614T171400' does not exist. Creating a new experiment.\n",
      "[I 2024-06-14 17:14:02,746] A new study created in memory with name: Study - lr(0.5) hds(25) bs(1) - 20240614T171400\n",
      "[I 2024-06-14 17:28:57,715] Trial 0 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.21959577383015977}. \n",
      "[I 2024-06-14 17:43:25,827] Trial 1 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.21500514532677525}. \n",
      "[I 2024-06-14 17:54:25,419] Trial 2 finished with values: [0.184, 0.184] and parameters: {'weight_decay': 0.44257706530185137}. \n",
      "[I 2024-06-14 18:05:01,077] Trial 3 finished with values: [0.196, 0.196] and parameters: {'weight_decay': 0.09553956957123408}. \n",
      "[I 2024-06-14 18:15:35,535] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.19098081093234126}. \n",
      "[I 2024-06-14 18:15:35,535] A new study created in memory with name: Study - lr(0.5) hds(25) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 18:18:26,044] Trial 0 finished with values: [0.09519999999999999, 0.1715932178932179] and parameters: {'weight_decay': 0.6449586195840052}. \n",
      "[I 2024-06-14 18:21:16,838] Trial 1 finished with values: [0.09839999999999999, 0.17085873015873015] and parameters: {'weight_decay': 0.49536770948002895}. \n",
      "[I 2024-06-14 18:24:09,967] Trial 2 finished with values: [0.12959999999999997, 0.25057840492840494] and parameters: {'weight_decay': 0.08863935515479908}. \n",
      "[I 2024-06-14 18:26:59,544] Trial 3 finished with values: [0.09319999999999999, 0.16461659451659452] and parameters: {'weight_decay': 0.7196140365157762}. \n",
      "[I 2024-06-14 18:29:50,905] Trial 4 finished with values: [0.09759999999999999, 0.17128725718725718] and parameters: {'weight_decay': 0.9510594235615238}. \n",
      "[I 2024-06-14 18:29:50,905] A new study created in memory with name: Study - lr(0.5) hds(25) bs(50) - 20240614T171400\n",
      "[I 2024-06-14 18:31:10,881] Trial 0 finished with values: [0.115, 0.21632394500391] and parameters: {'weight_decay': 0.4371160126247986}. \n",
      "[I 2024-06-14 18:32:31,349] Trial 1 finished with values: [0.1, 0.18067340504187468] and parameters: {'weight_decay': 0.5641343171601241}. \n",
      "[I 2024-06-14 18:33:50,984] Trial 2 finished with values: [0.109, 0.20000850169858903] and parameters: {'weight_decay': 0.467403276703812}. \n",
      "[I 2024-06-14 18:35:12,378] Trial 3 finished with values: [0.14220000000000002, 0.27226573980385704] and parameters: {'weight_decay': 0.28750732902784804}. \n",
      "[I 2024-06-14 18:36:33,088] Trial 4 finished with values: [0.1144, 0.20355822567253204] and parameters: {'weight_decay': 0.5128587122131456}. \n",
      "[I 2024-06-14 18:36:33,088] A new study created in memory with name: Study - lr(0.5) hds(25) bs(3350) - 20240614T171400\n",
      "[I 2024-06-14 18:37:29,648] Trial 0 finished with values: [0.12644776119402984, 0.20268156137405935] and parameters: {'weight_decay': 0.8625256787803871}. \n",
      "[I 2024-06-14 18:38:26,640] Trial 1 finished with values: [0.21567164179104478, 0.2872489935902312] and parameters: {'weight_decay': 0.2808686595599838}. \n",
      "[I 2024-06-14 18:39:23,349] Trial 2 finished with values: [0.1466686567164179, 0.22996352341938392] and parameters: {'weight_decay': 0.6410861306586343}. \n",
      "[I 2024-06-14 18:40:19,741] Trial 3 finished with values: [0.126644776119403, 0.20694491339749044] and parameters: {'weight_decay': 0.9660376767249336}. \n",
      "[I 2024-06-14 18:41:16,850] Trial 4 finished with values: [0.15186865671641792, 0.22976659877162234] and parameters: {'weight_decay': 0.5817183652027756}. \n",
      "[I 2024-06-14 18:41:16,850] A new study created in memory with name: Study - lr(0.5) hds(50) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.12644776119402984, 'best_f1': 0.20268156137405935}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 19:00:25,195] Trial 0 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.5446390218350867}. \n",
      "[I 2024-06-14 19:19:26,624] Trial 1 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.4552508560835999}. \n",
      "[I 2024-06-14 19:38:36,799] Trial 2 finished with values: [0.176, 0.176] and parameters: {'weight_decay': 0.778494863828787}. \n",
      "[I 2024-06-14 19:57:15,756] Trial 3 finished with values: [0.204, 0.204] and parameters: {'weight_decay': 0.0015404607994889024}. \n",
      "[I 2024-06-14 20:16:21,536] Trial 4 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.4629116463610798}. \n",
      "[I 2024-06-14 20:16:21,536] A new study created in memory with name: Study - lr(0.5) hds(50) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 20:19:19,133] Trial 0 finished with values: [0.09919999999999998, 0.17404293114293115] and parameters: {'weight_decay': 0.7830846297624006}. \n",
      "[I 2024-06-14 20:22:15,931] Trial 1 finished with values: [0.10119999999999998, 0.1758089244089244] and parameters: {'weight_decay': 0.553521745444784}. \n",
      "[I 2024-06-14 20:25:13,097] Trial 2 finished with values: [0.10599999999999998, 0.18637210197210197] and parameters: {'weight_decay': 0.24088230578302533}. \n",
      "[I 2024-06-14 20:28:09,912] Trial 3 finished with values: [0.09879999999999999, 0.17491002886002885] and parameters: {'weight_decay': 0.4039562992473984}. \n",
      "[I 2024-06-14 20:31:06,494] Trial 4 finished with values: [0.09519999999999999, 0.16834254634254633] and parameters: {'weight_decay': 0.49551030726824047}. \n",
      "[I 2024-06-14 20:31:06,494] A new study created in memory with name: Study - lr(0.5) hds(50) bs(50) - 20240614T171400\n",
      "[I 2024-06-14 20:32:30,911] Trial 0 finished with values: [0.0922, 0.16189633687505506] and parameters: {'weight_decay': 0.73364910869754}. \n",
      "[I 2024-06-14 20:33:53,461] Trial 1 finished with values: [0.11259999999999999, 0.22460881981143985] and parameters: {'weight_decay': 0.2461853596047678}. \n",
      "[I 2024-06-14 20:35:19,302] Trial 2 finished with values: [0.0968, 0.17859026488161636] and parameters: {'weight_decay': 0.5799001219339466}. \n",
      "[I 2024-06-14 20:36:41,561] Trial 3 finished with values: [0.09820000000000002, 0.17575017999718634] and parameters: {'weight_decay': 0.43262493283491316}. \n",
      "[I 2024-06-14 20:38:04,230] Trial 4 finished with values: [0.0968, 0.17327312323193564] and parameters: {'weight_decay': 0.6260976010715901}. \n",
      "[I 2024-06-14 20:38:04,230] A new study created in memory with name: Study - lr(0.5) hds(50) bs(3350) - 20240614T171400\n",
      "[I 2024-06-14 20:39:02,634] Trial 0 finished with values: [0.13822089552238806, 0.21794346373458615] and parameters: {'weight_decay': 0.5098284441073947}. \n",
      "[I 2024-06-14 20:40:01,291] Trial 1 finished with values: [0.12711044776119404, 0.21055531854360235] and parameters: {'weight_decay': 0.7683195687674663}. \n",
      "[I 2024-06-14 20:41:00,677] Trial 2 finished with values: [0.650841791044776, 0.6344454413901801] and parameters: {'weight_decay': 0.04467063279199616}. \n",
      "[I 2024-06-14 20:42:00,315] Trial 3 finished with values: [0.13413134328358212, 0.211405553851293] and parameters: {'weight_decay': 0.6323327995417789}. \n",
      "[I 2024-06-14 20:42:58,954] Trial 4 finished with values: [0.15983880597014924, 0.24375670803620972] and parameters: {'weight_decay': 0.5069297697321665}. \n",
      "[I 2024-06-14 20:42:58,954] A new study created in memory with name: Study - lr(0.5) hds(100) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.12711044776119404, 'best_f1': 0.21055531854360235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 21:03:31,545] Trial 0 finished with values: [0.184, 0.184] and parameters: {'weight_decay': 0.47037452419065745}. \n",
      "[I 2024-06-14 21:24:08,968] Trial 1 finished with values: [0.176, 0.176] and parameters: {'weight_decay': 0.7996287629957927}. \n",
      "[I 2024-06-14 21:44:35,693] Trial 2 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.3925602124016348}. \n",
      "[I 2024-06-14 22:04:51,970] Trial 3 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.12113575838280395}. \n",
      "[I 2024-06-14 22:25:27,193] Trial 4 finished with values: [0.18, 0.18] and parameters: {'weight_decay': 0.552613136185498}. \n",
      "[I 2024-06-14 22:25:27,193] A new study created in memory with name: Study - lr(0.5) hds(100) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 22:28:42,422] Trial 0 finished with values: [0.1148, 0.2119708791208791] and parameters: {'weight_decay': 0.09189964249114192}. \n",
      "[I 2024-06-14 22:31:53,717] Trial 1 finished with values: [0.10079999999999999, 0.1746550937950938] and parameters: {'weight_decay': 0.4548363964926019}. \n",
      "[I 2024-06-14 22:35:04,798] Trial 2 finished with values: [0.1, 0.17578826358826358] and parameters: {'weight_decay': 0.45459303443108856}. \n",
      "[I 2024-06-14 22:38:22,341] Trial 3 finished with values: [0.10119999999999998, 0.17825769785769785] and parameters: {'weight_decay': 0.2966864913798706}. \n",
      "[I 2024-06-14 22:41:35,220] Trial 4 finished with values: [0.09799999999999999, 0.16887715617715618] and parameters: {'weight_decay': 0.23529681481631629}. \n",
      "[I 2024-06-14 22:41:35,220] A new study created in memory with name: Study - lr(0.5) hds(100) bs(50) - 20240614T171400\n",
      "[I 2024-06-14 22:43:04,219] Trial 0 finished with values: [0.0892, 0.162796056832086] and parameters: {'weight_decay': 0.4120038398442698}. \n",
      "[I 2024-06-14 22:44:38,136] Trial 1 finished with values: [0.09, 0.16325570989137558] and parameters: {'weight_decay': 0.7334293012069532}. \n",
      "[I 2024-06-14 22:46:10,516] Trial 2 finished with values: [0.09880000000000001, 0.19291702159136614] and parameters: {'weight_decay': 0.16509905000598027}. \n",
      "[I 2024-06-14 22:47:40,565] Trial 3 finished with values: [0.0882, 0.15039467412119048] and parameters: {'weight_decay': 0.813824328060253}. \n",
      "[I 2024-06-14 22:49:10,240] Trial 4 finished with values: [0.09160000000000001, 0.16294464791496427] and parameters: {'weight_decay': 0.8806112542634088}. \n",
      "[I 2024-06-14 22:49:10,242] A new study created in memory with name: Study - lr(0.5) hds(100) bs(3350) - 20240614T171400\n",
      "[I 2024-06-14 22:50:13,468] Trial 0 finished with values: [0.11767164179104478, 0.19732679397846556] and parameters: {'weight_decay': 0.8893168974793102}. \n",
      "[I 2024-06-14 22:51:16,889] Trial 1 finished with values: [0.13170149253731345, 0.20960435470118607] and parameters: {'weight_decay': 0.6254512958647336}. \n",
      "[I 2024-06-14 22:52:20,376] Trial 2 finished with values: [0.11764776119402984, 0.19075030429565287] and parameters: {'weight_decay': 0.7942889368688288}. \n",
      "[I 2024-06-14 22:53:23,231] Trial 3 finished with values: [0.14002985074626867, 0.22047065458240225] and parameters: {'weight_decay': 0.443751498557575}. \n",
      "[I 2024-06-14 22:54:25,750] Trial 4 finished with values: [0.12125970149253731, 0.19505548278482912] and parameters: {'weight_decay': 0.8328219535143311}. \n",
      "[I 2024-06-14 22:54:25,752] A new study created in memory with name: Study - lr(1) hds(25) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.11764776119402984, 'best_f1': 0.19075030429565287}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 23:04:09,870] Trial 0 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.8077541123941098}. \n",
      "[I 2024-06-14 23:13:52,157] Trial 1 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.8911956487986815}. \n",
      "[I 2024-06-14 23:23:37,542] Trial 2 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.9287766725951332}. \n",
      "[I 2024-06-14 23:33:48,954] Trial 3 finished with values: [0.196, 0.196] and parameters: {'weight_decay': 0.08787365325399454}. \n",
      "[I 2024-06-14 23:44:15,680] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.028488046939587255}. \n",
      "[I 2024-06-14 23:44:15,680] A new study created in memory with name: Study - lr(1) hds(25) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 23:47:25,359] Trial 0 finished with values: [0.10119999999999998, 0.17892701002701006] and parameters: {'weight_decay': 0.48873330745605587}. \n",
      "[I 2024-06-14 23:50:31,307] Trial 1 finished with values: [0.098, 0.17355656565656566] and parameters: {'weight_decay': 0.34565641267523645}. \n",
      "[I 2024-06-14 23:53:18,906] Trial 2 finished with values: [0.09999999999999999, 0.175390934990935] and parameters: {'weight_decay': 0.500565983244663}. \n",
      "[I 2024-06-14 23:56:06,973] Trial 3 finished with values: [0.09999999999999999, 0.17575757575757575] and parameters: {'weight_decay': 0.956060042136712}. \n",
      "[I 2024-06-14 23:58:56,007] Trial 4 finished with values: [0.1008, 0.17773648573648576] and parameters: {'weight_decay': 0.786298019975178}. \n",
      "[I 2024-06-14 23:58:56,007] A new study created in memory with name: Study - lr(1) hds(25) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 00:00:23,723] Trial 0 finished with values: [0.1214, 0.25510200888769213] and parameters: {'weight_decay': 0.09256887090109078}. \n",
      "[I 2024-06-15 00:01:44,307] Trial 1 finished with values: [0.0722, 0.1297412521917442] and parameters: {'weight_decay': 0.61345496510177}. \n",
      "[I 2024-06-15 00:03:06,493] Trial 2 finished with values: [0.07680000000000001, 0.1370479954827781] and parameters: {'weight_decay': 0.940399211296342}. \n",
      "[I 2024-06-15 00:04:32,059] Trial 3 finished with values: [0.088, 0.16583643353876698] and parameters: {'weight_decay': 0.22000916028122283}. \n",
      "[I 2024-06-15 00:05:53,776] Trial 4 finished with values: [0.0692, 0.12239022461990831] and parameters: {'weight_decay': 0.6463253694901357}. \n",
      "[I 2024-06-15 00:05:53,777] A new study created in memory with name: Study - lr(1) hds(25) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 00:06:54,382] Trial 0 finished with values: [0.1419761194029851, 0.22808727233022888] and parameters: {'weight_decay': 0.23618038042214715}. \n",
      "[I 2024-06-15 00:07:54,920] Trial 1 finished with values: [0.11386865671641791, 0.19592595636178156] and parameters: {'weight_decay': 0.8478868598568371}. \n",
      "[I 2024-06-15 00:08:55,760] Trial 2 finished with values: [0.12284179104477612, 0.20706804361098763] and parameters: {'weight_decay': 0.6388473550580727}. \n",
      "[I 2024-06-15 00:09:56,927] Trial 3 finished with values: [0.12433432835820897, 0.21499166053022703] and parameters: {'weight_decay': 0.5312672345130159}. \n",
      "[I 2024-06-15 00:10:57,723] Trial 4 finished with values: [0.11536716417910448, 0.2005148646451018] and parameters: {'weight_decay': 0.9569397817320676}. \n",
      "[I 2024-06-15 00:10:57,724] A new study created in memory with name: Study - lr(1) hds(50) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.11386865671641791, 'best_f1': 0.19592595636178156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 00:28:53,936] Trial 0 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.43319070458962194}. \n",
      "[I 2024-06-15 00:46:49,282] Trial 1 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.36149240461487325}. \n",
      "[I 2024-06-15 01:03:51,873] Trial 2 finished with values: [0.196, 0.196] and parameters: {'weight_decay': 0.6142344864190896}. \n",
      "[I 2024-06-15 01:21:34,084] Trial 3 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.10759361402933605}. \n",
      "[I 2024-06-15 01:38:35,613] Trial 4 finished with values: [0.18, 0.18] and parameters: {'weight_decay': 0.523187461382211}. \n",
      "[I 2024-06-15 01:38:35,613] A new study created in memory with name: Study - lr(1) hds(50) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 01:41:35,861] Trial 0 finished with values: [0.10879999999999998, 0.19225087135087138] and parameters: {'weight_decay': 0.036662862954002486}. \n",
      "[I 2024-06-15 01:44:35,409] Trial 1 finished with values: [0.11760000000000001, 0.2146398727198727] and parameters: {'weight_decay': 0.014970211254698848}. \n",
      "[I 2024-06-15 01:47:28,428] Trial 2 finished with values: [0.09759999999999999, 0.17195870795870796] and parameters: {'weight_decay': 0.9003063287212307}. \n",
      "[I 2024-06-15 01:50:26,124] Trial 3 finished with values: [0.10119999999999998, 0.17699989121989124] and parameters: {'weight_decay': 0.28091651808737145}. \n",
      "[I 2024-06-15 01:53:17,689] Trial 4 finished with values: [0.09919999999999998, 0.1754768897768898] and parameters: {'weight_decay': 0.6796657484753943}. \n",
      "[I 2024-06-15 01:53:17,689] A new study created in memory with name: Study - lr(1) hds(50) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 01:54:44,572] Trial 0 finished with values: [0.078, 0.14489336382394158] and parameters: {'weight_decay': 0.2561813020669501}. \n",
      "[I 2024-06-15 01:56:11,591] Trial 1 finished with values: [0.07479999999999999, 0.13315134067051687] and parameters: {'weight_decay': 0.8642617326758352}. \n",
      "[I 2024-06-15 01:57:41,304] Trial 2 finished with values: [0.082, 0.15239711033702857] and parameters: {'weight_decay': 0.15554326475510075}. \n",
      "[I 2024-06-15 01:59:10,173] Trial 3 finished with values: [0.07180000000000002, 0.12847061890822023] and parameters: {'weight_decay': 0.4195926330379432}. \n",
      "[I 2024-06-15 02:00:38,555] Trial 4 finished with values: [0.0758, 0.13632719568969942] and parameters: {'weight_decay': 0.3754229723139094}. \n",
      "[I 2024-06-15 02:00:38,555] A new study created in memory with name: Study - lr(1) hds(50) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 02:01:41,225] Trial 0 finished with values: [0.11530149253731344, 0.1955192444341067] and parameters: {'weight_decay': 0.5970874561572252}. \n",
      "[I 2024-06-15 02:02:44,778] Trial 1 finished with values: [0.36514029850746266, 0.36242994730283284] and parameters: {'weight_decay': 0.05466484635305201}. \n",
      "[I 2024-06-15 02:03:48,349] Trial 2 finished with values: [0.11907462686567165, 0.19480953133148823] and parameters: {'weight_decay': 0.2893438867984909}. \n",
      "[I 2024-06-15 02:04:51,571] Trial 3 finished with values: [0.1204955223880597, 0.19940340111035487] and parameters: {'weight_decay': 0.38854890017036336}. \n",
      "[I 2024-06-15 02:05:54,907] Trial 4 finished with values: [0.11682985074626866, 0.1940043358949208] and parameters: {'weight_decay': 0.6035059176739791}. \n",
      "[I 2024-06-15 02:05:54,907] A new study created in memory with name: Study - lr(1) hds(100) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.11530149253731344, 'best_f1': 0.1955192444341067}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 02:23:51,862] Trial 0 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.9715069529194521}. \n",
      "[I 2024-06-15 02:41:48,567] Trial 1 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.78589074845382}. \n",
      "[I 2024-06-15 03:01:01,906] Trial 2 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.41956517210792976}. \n",
      "[I 2024-06-15 03:18:59,344] Trial 3 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.8452990388166546}. \n",
      "[I 2024-06-15 03:36:54,985] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.6592282579658413}. \n",
      "[I 2024-06-15 03:36:54,985] A new study created in memory with name: Study - lr(1) hds(100) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 03:40:01,106] Trial 0 finished with values: [0.09839999999999997, 0.17169175084175084] and parameters: {'weight_decay': 0.7229758223449322}. \n",
      "[I 2024-06-15 03:43:15,125] Trial 1 finished with values: [0.09799999999999999, 0.17388724941724945] and parameters: {'weight_decay': 0.49652837111178894}. \n",
      "[I 2024-06-15 03:46:20,738] Trial 2 finished with values: [0.0996, 0.17472302142302146] and parameters: {'weight_decay': 0.5819402185600685}. \n",
      "[I 2024-06-15 03:49:22,568] Trial 3 finished with values: [0.10239999999999999, 0.17888706848706848] and parameters: {'weight_decay': 0.8648761879858713}. \n",
      "[I 2024-06-15 03:52:26,399] Trial 4 finished with values: [0.1024, 0.1789069597069597] and parameters: {'weight_decay': 0.8003784868145967}. \n",
      "[I 2024-06-15 03:52:26,399] A new study created in memory with name: Study - lr(1) hds(100) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 03:53:57,531] Trial 0 finished with values: [0.0698, 0.12343093042223478] and parameters: {'weight_decay': 0.9682414591499549}. \n",
      "[I 2024-06-15 03:55:37,030] Trial 1 finished with values: [0.0824, 0.1495506988606733] and parameters: {'weight_decay': 0.33138249695087185}. \n",
      "[I 2024-06-15 03:57:19,861] Trial 2 finished with values: [0.09919999999999998, 0.19441103503607957] and parameters: {'weight_decay': 0.067873348509183}. \n",
      "[I 2024-06-15 03:58:54,976] Trial 3 finished with values: [0.084, 0.14688287499344863] and parameters: {'weight_decay': 0.44231194824531467}. \n",
      "[I 2024-06-15 04:00:35,436] Trial 4 finished with values: [0.079, 0.14027568000464602] and parameters: {'weight_decay': 0.32585734298718044}. \n",
      "[I 2024-06-15 04:00:35,436] A new study created in memory with name: Study - lr(1) hds(100) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 04:01:41,625] Trial 0 finished with values: [0.11038208955223883, 0.18908622916427317] and parameters: {'weight_decay': 0.703336085654078}. \n",
      "[I 2024-06-15 04:02:49,213] Trial 1 finished with values: [0.12429850746268656, 0.21314249550683761] and parameters: {'weight_decay': 0.2332278806247643}. \n",
      "[I 2024-06-15 04:03:56,147] Trial 2 finished with values: [0.11155820895522388, 0.18825560511162115] and parameters: {'weight_decay': 0.648316911405224}. \n",
      "[I 2024-06-15 04:05:04,383] Trial 3 finished with values: [0.1092179104477612, 0.18565819725180752] and parameters: {'weight_decay': 0.6101215697724652}. \n",
      "[I 2024-06-15 04:06:14,253] Trial 4 finished with values: [0.10873432835820895, 0.1941751753254041] and parameters: {'weight_decay': 0.9273425510931056}. \n",
      "[I 2024-06-15 04:06:14,253] A new study created in memory with name: Study - lr(10) hds(25) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.1092179104477612, 'best_f1': 0.18565819725180752}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 04:15:43,390] Trial 0 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.8153151002896245}. \n",
      "[I 2024-06-15 04:25:15,845] Trial 1 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.948927162147763}. \n",
      "[I 2024-06-15 04:34:39,534] Trial 2 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.7234808057757657}. \n",
      "[I 2024-06-15 04:44:05,589] Trial 3 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.6993623573611013}. \n",
      "[I 2024-06-15 04:53:33,130] Trial 4 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.3034188447206517}. \n",
      "[I 2024-06-15 04:53:33,130] A new study created in memory with name: Study - lr(10) hds(25) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 04:56:19,228] Trial 0 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9588507205556946}. \n",
      "[I 2024-06-15 04:59:03,146] Trial 1 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.3522450444911105}. \n",
      "[I 2024-06-15 05:01:49,928] Trial 2 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9755578230826403}. \n",
      "[I 2024-06-15 05:04:37,280] Trial 3 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.3957974705607464}. \n",
      "[I 2024-06-15 05:07:27,747] Trial 4 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.5272530632898731}. \n",
      "[I 2024-06-15 05:07:27,747] A new study created in memory with name: Study - lr(10) hds(25) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 05:08:51,064] Trial 0 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.9797993959223117}. \n",
      "[I 2024-06-15 05:10:18,746] Trial 1 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.21876524939082392}. \n",
      "[I 2024-06-15 05:11:43,946] Trial 2 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.35316310662527245}. \n",
      "[I 2024-06-15 05:13:16,628] Trial 3 finished with values: [0.07, 0.12663278750235274] and parameters: {'weight_decay': 0.13221285182383274}. \n",
      "[I 2024-06-15 05:14:42,181] Trial 4 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.35672646010386955}. \n",
      "[I 2024-06-15 05:14:42,181] A new study created in memory with name: Study - lr(10) hds(25) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 05:15:47,318] Trial 0 finished with values: [0.10754626865671642, 0.18878246304692892] and parameters: {'weight_decay': 0.07436721195324679}. \n",
      "[I 2024-06-15 05:16:52,986] Trial 1 finished with values: [0.10383880597014926, 0.18285509869009578] and parameters: {'weight_decay': 0.01691536455375388}. \n",
      "[I 2024-06-15 05:17:58,690] Trial 2 finished with values: [0.10554029850746269, 0.18477119119768778] and parameters: {'weight_decay': 0.01769727713179969}. \n",
      "[I 2024-06-15 05:19:03,187] Trial 3 finished with values: [0.09521791044776119, 0.16838521032625464] and parameters: {'weight_decay': 0.9160756001709291}. \n",
      "[I 2024-06-15 05:20:10,664] Trial 4 finished with values: [0.0939582089552239, 0.17174139689535695] and parameters: {'weight_decay': 0.6584390041817857}. \n",
      "[I 2024-06-15 05:20:10,664] A new study created in memory with name: Study - lr(10) hds(50) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.09521791044776119, 'best_f1': 0.16838521032625464}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 05:37:00,748] Trial 0 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.5983167038913301}. \n",
      "[I 2024-06-15 05:53:57,898] Trial 1 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.8530436350201308}. \n",
      "[I 2024-06-15 06:12:08,692] Trial 2 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.033576507924941316}. \n",
      "[I 2024-06-15 06:30:30,320] Trial 3 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.07502623203456486}. \n",
      "[I 2024-06-15 06:49:02,280] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.0900948638506418}. \n",
      "[I 2024-06-15 06:49:02,280] A new study created in memory with name: Study - lr(10) hds(50) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 06:52:18,459] Trial 0 finished with values: [0.10119999999999998, 0.17154312354312357] and parameters: {'weight_decay': 0.12814785837400428}. \n",
      "[I 2024-06-15 06:55:11,191] Trial 1 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9243009741278334}. \n",
      "[I 2024-06-15 06:58:03,474] Trial 2 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.8157005057525126}. \n",
      "[I 2024-06-15 07:00:56,590] Trial 3 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.8904752494379335}. \n",
      "[I 2024-06-15 07:04:00,270] Trial 4 finished with values: [0.09919999999999998, 0.17333102453102453] and parameters: {'weight_decay': 0.06094815539532095}. \n",
      "[I 2024-06-15 07:04:00,270] A new study created in memory with name: Study - lr(10) hds(50) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 07:05:33,740] Trial 0 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.7081917289164852}. \n",
      "[I 2024-06-15 07:07:00,510] Trial 1 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.943459483629794}. \n",
      "[I 2024-06-15 07:08:32,967] Trial 2 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.4901724387745128}. \n",
      "[I 2024-06-15 07:10:00,369] Trial 3 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.36495960569082186}. \n",
      "[I 2024-06-15 07:11:36,581] Trial 4 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.19331924891050403}. \n",
      "[I 2024-06-15 07:11:36,581] A new study created in memory with name: Study - lr(10) hds(50) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 07:12:42,568] Trial 0 finished with values: [0.09560597014925375, 0.17409795795781877] and parameters: {'weight_decay': 0.6653931191440079}. \n",
      "[I 2024-06-15 07:13:48,405] Trial 1 finished with values: [0.0941492537313433, 0.16941141544823762] and parameters: {'weight_decay': 0.9149889235337078}. \n",
      "[I 2024-06-15 07:14:54,825] Trial 2 finished with values: [0.09520000000000002, 0.17345821199454164] and parameters: {'weight_decay': 0.9793230741048037}. \n",
      "[I 2024-06-15 07:16:01,265] Trial 3 finished with values: [0.09525373134328359, 0.17350442715393616] and parameters: {'weight_decay': 0.6816412509081851}. \n",
      "[I 2024-06-15 07:17:12,598] Trial 4 finished with values: [0.10674626865671642, 0.1805587790586577] and parameters: {'weight_decay': 0.01176490228244394}. \n",
      "[I 2024-06-15 07:17:12,598] A new study created in memory with name: Study - lr(10) hds(100) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.0941492537313433, 'best_f1': 0.16941141544823762}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 07:34:42,608] Trial 0 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.32985694591643283}. \n",
      "[I 2024-06-15 07:52:11,984] Trial 1 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.47150346490262296}. \n",
      "[I 2024-06-15 08:09:45,976] Trial 2 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.9262503398897733}. \n",
      "[I 2024-06-15 08:27:14,987] Trial 3 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.6928725788725207}. \n",
      "[I 2024-06-15 08:44:40,724] Trial 4 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.7535128077498956}. \n",
      "[I 2024-06-15 08:44:40,725] A new study created in memory with name: Study - lr(10) hds(100) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 08:47:43,129] Trial 0 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9757882840054308}. \n",
      "[I 2024-06-15 08:51:01,575] Trial 1 finished with values: [0.10039999999999998, 0.177359595959596] and parameters: {'weight_decay': 0.07295314640314535}. \n",
      "[I 2024-06-15 08:54:24,786] Trial 2 finished with values: [0.1044, 0.18138192474192477] and parameters: {'weight_decay': 0.026643986907717538}. \n",
      "[I 2024-06-15 08:57:27,031] Trial 3 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.5176794343725942}. \n",
      "[I 2024-06-15 09:00:28,196] Trial 4 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.325232402007046}. \n",
      "[I 2024-06-15 09:00:28,196] A new study created in memory with name: Study - lr(10) hds(100) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 09:01:59,113] Trial 0 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.45996678833514826}. \n",
      "[I 2024-06-15 09:03:36,143] Trial 1 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.5251078090003678}. \n",
      "[I 2024-06-15 09:05:10,691] Trial 2 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.3119613264967052}. \n",
      "[I 2024-06-15 09:06:56,802] Trial 3 finished with values: [0.1154, 0.2164697445779392] and parameters: {'weight_decay': 0.0006480366471825574}. \n",
      "[I 2024-06-15 09:08:43,326] Trial 4 finished with values: [0.08339999999999999, 0.15054519615904052] and parameters: {'weight_decay': 0.06098757560407173}. \n",
      "[I 2024-06-15 09:08:43,328] A new study created in memory with name: Study - lr(10) hds(100) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 09:09:52,121] Trial 0 finished with values: [0.09514626865671644, 0.17301788007844593] and parameters: {'weight_decay': 0.7035880242818825}. \n",
      "[I 2024-06-15 09:11:00,808] Trial 1 finished with values: [0.09632238805970152, 0.1757770589741936] and parameters: {'weight_decay': 0.6760399758031632}. \n",
      "[I 2024-06-15 09:12:13,023] Trial 2 finished with values: [0.09503283582089554, 0.17307238607982525] and parameters: {'weight_decay': 0.4610140427998896}. \n",
      "[I 2024-06-15 09:13:25,959] Trial 3 finished with values: [0.09632835820895524, 0.17495988346343835] and parameters: {'weight_decay': 0.3777750231402919}. \n",
      "[I 2024-06-15 09:14:35,827] Trial 4 finished with values: [0.09536716417910449, 0.17339598181975885] and parameters: {'weight_decay': 0.4853528621657173}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.09514626865671644, 'best_f1': 0.17301788007844593}\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 1\n",
      "Best Accuracy: 0.184, Best F1 Score: 0.184\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 10\n",
      "Best Accuracy: 0.09319999999999999, Best F1 Score: 0.16461659451659452\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 50\n",
      "Best Accuracy: 0.1, Best F1 Score: 0.18067340504187468\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 3350\n",
      "Best Accuracy: 0.12644776119402984, Best F1 Score: 0.20268156137405935\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 1\n",
      "Best Accuracy: 0.176, Best F1 Score: 0.176\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 10\n",
      "Best Accuracy: 0.09519999999999999, Best F1 Score: 0.16834254634254633\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 50\n",
      "Best Accuracy: 0.0922, Best F1 Score: 0.16189633687505506\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 3350\n",
      "Best Accuracy: 0.12711044776119404, Best F1 Score: 0.21055531854360235\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 1\n",
      "Best Accuracy: 0.176, Best F1 Score: 0.176\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 10\n",
      "Best Accuracy: 0.09799999999999999, Best F1 Score: 0.16887715617715618\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 50\n",
      "Best Accuracy: 0.0882, Best F1 Score: 0.15039467412119048\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 3350\n",
      "Best Accuracy: 0.11764776119402984, Best F1 Score: 0.19075030429565287\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 1\n",
      "Best Accuracy: 0.196, Best F1 Score: 0.196\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 10\n",
      "Best Accuracy: 0.098, Best F1 Score: 0.17355656565656566\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 50\n",
      "Best Accuracy: 0.0692, Best F1 Score: 0.12239022461990831\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 3350\n",
      "Best Accuracy: 0.11386865671641791, Best F1 Score: 0.19592595636178156\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 1\n",
      "Best Accuracy: 0.18, Best F1 Score: 0.18\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 10\n",
      "Best Accuracy: 0.09759999999999999, Best F1 Score: 0.17195870795870796\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 50\n",
      "Best Accuracy: 0.07180000000000002, Best F1 Score: 0.12847061890822023\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 3350\n",
      "Best Accuracy: 0.11530149253731344, Best F1 Score: 0.1955192444341067\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 1\n",
      "Best Accuracy: 0.188, Best F1 Score: 0.188\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 10\n",
      "Best Accuracy: 0.09839999999999997, Best F1 Score: 0.17169175084175084\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 50\n",
      "Best Accuracy: 0.0698, Best F1 Score: 0.12343093042223478\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 3350\n",
      "Best Accuracy: 0.1092179104477612, Best F1 Score: 0.18565819725180752\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 1\n",
      "Best Accuracy: 0.0, Best F1 Score: 0.0\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 10\n",
      "Best Accuracy: 0.04, Best F1 Score: 0.07272727272727274\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 50\n",
      "Best Accuracy: 0.07, Best F1 Score: 0.12663278750235274\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 3350\n",
      "Best Accuracy: 0.09521791044776119, Best F1 Score: 0.16838521032625464\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 1\n",
      "Best Accuracy: 0.0, Best F1 Score: 0.0\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 10\n",
      "Best Accuracy: 0.04, Best F1 Score: 0.07272727272727274\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 50\n",
      "Best Accuracy: 0.07, Best F1 Score: 0.12987012987012989\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 3350\n",
      "Best Accuracy: 0.0941492537313433, Best F1 Score: 0.16941141544823762\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 1\n",
      "Best Accuracy: 0.0, Best F1 Score: 0.0\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 10\n",
      "Best Accuracy: 0.04, Best F1 Score: 0.07272727272727274\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 50\n",
      "Best Accuracy: 0.07, Best F1 Score: 0.12987012987012989\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 3350\n",
      "Best Accuracy: 0.09514626865671644, Best F1 Score: 0.17301788007844593\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Assuming the rest of your imports and setup code remains the same\n",
    "def train_and_evaluate_model(model, loss_func, optimizer, train_dataloader, val_dataloader, n_epochs, lr, hds, bs,weight_decay):   \n",
    "    with mlflow.start_run(run_name=f\"Testi \", nested = True):  # Name each run based on the learning rate\n",
    "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "        mlflow.log_param(\"batch_size\", bs)\n",
    "        mlflow.log_param(\"hidden_dim\", hds)\n",
    "        mlflow.log_param(\"lr\", lr)        \n",
    "\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Training loop\n",
    "            for inputs, targets in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_func(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            training_loss = loss\n",
    "            mlflow.log_metric(\"loss\", training_loss, step = epoch)\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            with torch.no_grad():\n",
    "                total_targets = 0\n",
    "                total_outputs = 0\n",
    "                for inputs, targets in val_dataloader:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_func(outputs, targets)\n",
    "                    val_losses.append(loss.item())\n",
    "\n",
    "                    _, preds = torch.max(outputs, dim=1)\n",
    "                    total_targets += targets.size(0)\n",
    "                    total_outputs += torch.sum(preds == targets.data)\n",
    "\n",
    "            total_labels = targets.numpy()\n",
    "            total_preds = preds.numpy()\n",
    "            acc = accuracy_score(total_labels, total_preds)\n",
    "            # precision = precision_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "            # recall = recall_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "            f1 = f1_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "\n",
    "            # acc = total_outputs / total_targets\n",
    "            # f1 = f1_score(targets.numpy(), preds.numpy())  # Assuming targets and preds are NumPy arrays\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            accuracies.append(acc)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            mlflow.log_metric(\"val_loss\", loss, step = epoch)\n",
    "            mlflow.log_metric(\"diff_loss_tr_ts\", training_loss-loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"accuracy\", acc, step = epoch)\n",
    "            # mlflow.log_metric(\"precision\", precision, step = epoch)\n",
    "            # mlflow.log_metric(\"recall\", recall, step = epoch)\n",
    "            mlflow.log_metric(\"f1\", f1, step = epoch)  \n",
    "\n",
    "        # return train_losses, val_losses, accuracies, f1_scores\n",
    "    return train_losses, val_losses, accuracies, f1_scores\n",
    "\n",
    "\n",
    "def objective(trial, lr, hds, bs, X_train, y_train):\n",
    "    text = \"Experiment - lr({lr}) hds({hds}) bs({bs})\".format(lr =lr,hds=hds,bs =bs)\n",
    "    with mlflow.start_run(run_name=text, experiment_id = mlflow_exp.experiment_id):\n",
    "        \n",
    "        # Suggest regularization parameter using the trial object\n",
    "        weight_decay = trial.suggest_float('weight_decay', 1e-5, 1)\n",
    "        \n",
    "        # Initialize the model with fixed hyperparameters and suggested regularization\n",
    "        model = NeuralNetwork(input_size=X_train.shape[1], hidden_dim=hds, output_size=10).to(device)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Perform k-fold cross-validation\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = {\"accuracy\": [], \"f1\": []}\n",
    "\n",
    "        for train_index, val_index in skf.split(X_train, y_train):\n",
    "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "            train_dataloader_fold = DataLoader(custom_mnist_dataset(X=X_train_fold, y=y_train_fold), batch_size=bs)\n",
    "            val_dataloader_fold = DataLoader(custom_mnist_dataset(X=X_val_fold, y=y_val_fold), batch_size=bs)\n",
    "\n",
    "            # Train and evaluate the model for this fold\n",
    "            train_loss, test_loss, accuracy, f1 = train_and_evaluate_model(\n",
    "                model, loss_func, optimizer, train_dataloader_fold, val_dataloader_fold, n_epochs=50, \n",
    "                lr=lr, hds=hds, bs=bs, weight_decay = weight_decay)\n",
    "\n",
    "            # Calculate average scores across all folds\n",
    "            cv_scores[\"accuracy\"].append(accuracy)\n",
    "            cv_scores[\"f1\"].append(f1)\n",
    "\n",
    "        # Return the average cross-validated scores\n",
    "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "        mlflow.log_param(\"batch_size\", bs)\n",
    "        mlflow.log_param(\"hidden_dim\", hds)\n",
    "        mlflow.log_param(\"lr\", lr)      \n",
    "        mlflow.log_metric(\"cv-accuracy\", np.mean(cv_scores[\"accuracy\"]))\n",
    "        mlflow.log_metric(\"cv-f1\",  np.mean(cv_scores[\"f1\"]))  \n",
    "                \n",
    "        return np.mean(cv_scores[\"accuracy\"]), np.mean(cv_scores[\"f1\"])\n",
    "\n",
    "# Fixed hyperparameters\n",
    "fixed_hyperparams = {\n",
    "    'learning_rates': [0.5, 1, 10],\n",
    "    'hidden_dim_sizes': [25, 50, 100],\n",
    "    'batch_sizes': [1, 10, 50, len(training_data)],\n",
    "}\n",
    "\n",
    "# watch out for n_trials, n_splits, n_epochs\n",
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.autolog()\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Convert to string in the format 'YYYY-MM-DD HH:MM:SS'\n",
    "formatted_now = now.strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "print(formatted_now)\n",
    "\n",
    "mlflow_exp = mlflow.set_experiment(experiment_name  = 'TP1ML - '+formatted_now)\n",
    "\n",
    "# Iterate over fixed hyperparameters\n",
    "best_results = {}\n",
    "for lr in fixed_hyperparams['learning_rates']:\n",
    "    for hds in fixed_hyperparams['hidden_dim_sizes']:\n",
    "        for bs in fixed_hyperparams['batch_sizes']:\n",
    "            # Create an Optuna study for each combination\n",
    "            # study = optuna.create_study(direction=('minimize', ('accuracy', 'f1')))\n",
    "            study_name =  \"Study - lr({lr}) hds({hds}) bs({bs}) - \".format(lr =lr,hds=hds,bs =bs)+formatted_now\n",
    "            study = optuna.create_study(directions=[\"minimize\", \"minimize\"],study_name =study_name )\n",
    "            study.optimize(lambda t: objective(t, lr, hds, bs, X_train, y_train), n_trials=5)  # Adjust n_trials as needed\n",
    "            \n",
    "            # Record the best trial\n",
    "            best_trial = study.best_trials[0]\n",
    "            best_accuracy = best_trial.values[0]\n",
    "            best_f1 = best_trial.values[1]\n",
    "            \n",
    "            # Record best results\n",
    "            best_results[(lr, hds, bs)] = {\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'best_f1': best_f1,\n",
    "            }\n",
    "        \n",
    "        print(best_results[(lr, hds, bs)])\n",
    "\n",
    "# Print the best results\n",
    "for (lr, hds, bs), result in best_results.items():\n",
    "    print(f\"Learning Rate: {lr}, Hidden Dimension Size: {hds}, Batch Size: {bs}\")\n",
    "    print(f\"Best Accuracy: {result['best_accuracy']}, Best F1 Score: {result['best_f1']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
