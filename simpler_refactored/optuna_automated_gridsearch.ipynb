{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7   0  84 185 159 151  60  36 222 254 241 198 170  52  67 114  72 163\n",
      " 227 225 250 229 140  17  66  14  59  21 236 106  83 253 209  18  22 233\n",
      " 255 129 238  44 249  62 133 187   5   9 205 248  58 126 182  75 251 240\n",
      "  57  19 221 166   3 203 219  35  38  77  31 224 115   1  61 242 121  40\n",
      " 207]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  7  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  2  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  784  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbZklEQVR4nO3df3DU9b3v8dfyIwtosjGEZBMJGFBBReKIEDMoRcmQxHO9gEwv/ui54Dg40uApUquTjoq0nZuKM9ark8K5Z1pSpyLKHIGRa+nVYMJVA71EGC5TTQkTSziQoLTJhiAhks/9g+u2C4n0u+zmnV2ej5nvDNn9fvJ9+3X1yZfdfPE555wAABhgQ6wHAABcnggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMcx6gPP19vbq6NGjSk1Nlc/nsx4HAOCRc06dnZ3Kzc3VkCH9X+cMugAdPXpUeXl51mMAAC5RS0uLxo4d2+/zgy5AqampkqQ7dI+GabjxNAAAr75Wjz7Uu+H/n/cnbgGqqqrSiy++qNbWVhUUFOjVV1/VjBkzLrrumz92G6bhGuYjQACQcP7/HUYv9jZKXD6E8Oabb2rlypVatWqVPvnkExUUFKikpETHjx+Px+EAAAkoLgF66aWXtHTpUj388MO68cYbtW7dOo0aNUq//vWv43E4AEACinmAzpw5o4aGBhUXF//tIEOGqLi4WPX19Rfs393drVAoFLEBAJJfzAP05Zdf6uzZs8rOzo54PDs7W62trRfsX1lZqUAgEN74BBwAXB7MfxC1oqJCHR0d4a2lpcV6JADAAIj5p+AyMzM1dOhQtbW1RTze1tamYDB4wf5+v19+vz/WYwAABrmYXwGlpKRo2rRpqqmpCT/W29urmpoaFRUVxfpwAIAEFZefA1q5cqUWL16s2267TTNmzNDLL7+srq4uPfzww/E4HAAgAcUlQIsWLdIXX3yh5557Tq2trbrlllu0ffv2Cz6YAAC4fPmcc856iL8XCoUUCAQ0W/O4EwIAJKCvXY9qtVUdHR1KS0vrdz/zT8EBAC5PBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIlh1gMAF3P2rls9r1n+P96K6lhrr7s2qnWITuei2z2vSd/3pec1ZxubPK9B/HEFBAAwQYAAACZiHqDnn39ePp8vYps8eXKsDwMASHBxeQ/opptu0vvvv/+3gwzjrSYAQKS4lGHYsGEKBoPx+NYAgCQRl/eADh48qNzcXE2YMEEPPfSQDh8+3O++3d3dCoVCERsAIPnFPECFhYWqrq7W9u3btXbtWjU3N+vOO+9UZ2dnn/tXVlYqEAiEt7y8vFiPBAAYhGIeoLKyMn33u9/V1KlTVVJSonfffVft7e16662+fy6joqJCHR0d4a2lpSXWIwEABqG4fzogPT1d119/vZqa+v5BML/fL7/fH+8xAACDTNx/DujkyZM6dOiQcnJy4n0oAEACiXmAnnzySdXV1enzzz/Xxx9/rAULFmjo0KF64IEHYn0oAEACi/kfwR05ckQPPPCATpw4oTFjxuiOO+7Qrl27NGbMmFgfCgCQwGIeoI0bN8b6W+Iy9+cS7+8RZgw9GYdJEGut/3TG85qef/b+BzcZ/8nzEgwA7gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI+19IB/w93/AUz2vuvntf7AfBoJC6d4TnNf/lkTrPaz5IH+t5jSSdbe+Iah3+MVwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAR3w8aA6lxwq+c1r1z9quc1N2xZ7nmNJF2n3VGtQ3S6r3Ke1/zLVZ95XlObeoPnNZIk7oYdV1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpouZm3uJ5TdUL/93zmt+GxnteM/mZP3leI0lno1qFaBXNPWA9AgxxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpIjaXytOeV4zdtjXntesfPyfPK8Z/tcGz2twaYblBD2vWT9uu+c1PY7fNycL/k0CAEwQIACACc8B2rlzp+69917l5ubK5/Npy5YtEc875/Tcc88pJydHI0eOVHFxsQ4ePBireQEAScJzgLq6ulRQUKCqqqo+n1+zZo1eeeUVrVu3Trt379YVV1yhkpISnT59+pKHBQAkD88fQigrK1NZWVmfzznn9PLLL+uZZ57RvHnzJEmvvfaasrOztWXLFt1///2XNi0AIGnE9D2g5uZmtba2qri4OPxYIBBQYWGh6uvr+1zT3d2tUCgUsQEAkl9MA9Ta2ipJys7Ojng8Ozs7/Nz5KisrFQgEwlteXl4sRwIADFLmn4KrqKhQR0dHeGtpabEeCQAwAGIaoGDw3A+itbW1RTze1tYWfu58fr9faWlpERsAIPnFNED5+fkKBoOqqakJPxYKhbR7924VFRXF8lAAgATn+VNwJ0+eVFNTU/jr5uZm7du3TxkZGRo3bpxWrFihn/3sZ7ruuuuUn5+vZ599Vrm5uZo/f34s5wYAJDjPAdqzZ4/uuuuu8NcrV66UJC1evFjV1dV66qmn1NXVpUcffVTt7e264447tH37do0YMSJ2UwMAEp7POeesh/h7oVBIgUBAszVPw3zDrce5LJxYGt0fj2565kXPazZ3TvW85vdTeF8wEfzp36Z7X3PPOs9rFn9efPGdzvOXu73fOFeSXHd3VOsud1+7HtVqqzo6Or71fX3zT8EBAC5PBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMOH5r2NA8hky/8uo1uUO83te86sNpZ7XjNXHntfg0gy9aZLnNb+d86+e13S7Hs9rDr90vec1V3Tv9rwG8ccVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRJpmhY8Z4XvPM9f8zDpP0bex/48aiieCz76d7XnOb/6znNVV/vdHzmiv+nRuLJguugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMNMn4Ro3wvKZkVEdUx5rxf/6r5zVBfRrVsTCwMq/5y4Ac5/Xm2zyvydSf4jAJLHAFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakSab3L+2e1/z0i1ujOtaDE/d4XrMzZ6LnNV8fa/W8BucMG58X1bqPbtkYxSrvv5/9aldmFMfhZqTJgisgAIAJAgQAMOE5QDt37tS9996r3Nxc+Xw+bdmyJeL5JUuWyOfzRWylpaWxmhcAkCQ8B6irq0sFBQWqqqrqd5/S0lIdO3YsvL3xxhuXNCQAIPl4/hBCWVmZysrKvnUfv9+vYDAY9VAAgOQXl/eAamtrlZWVpUmTJmnZsmU6ceJEv/t2d3crFApFbACA5BfzAJWWluq1115TTU2NXnjhBdXV1amsrExnz57tc//KykoFAoHwlpcX3cdGAQCJJeY/B3T//feHf33zzTdr6tSpmjhxomprazVnzpwL9q+oqNDKlSvDX4dCISIEAJeBuH8Me8KECcrMzFRTU1Ofz/v9fqWlpUVsAIDkF/cAHTlyRCdOnFBOTk68DwUASCCe/wju5MmTEVczzc3N2rdvnzIyMpSRkaHVq1dr4cKFCgaDOnTokJ566ilde+21KikpiengAIDE5jlAe/bs0V133RX++pv3bxYvXqy1a9dq//79+s1vfqP29nbl5uZq7ty5+ulPfyq/3x+7qQEACc9zgGbPni3nXL/P//73v7+kgXBpejs7Pa/5X/8xOapj/e9bNnhec2xbwPtx/rXI85rBrv3G/v8b6s+V13R4XnN77uee10hSr3qjWueVz/tpQBLhXnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEfO/khuJ56rVI6Ja953nH/C8ZvOUas9rXlhV73nNYLene6jnNWej+P3ibSlnPK85xxflOm/Gvfp/Pa8ZmPt0YyBwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpJD+4P2GkJIUuMf7mn+e/S+e17Rf5/d+oEFu9L8NzA1W/+Ptm6Ja11BYHdtB+tHb2Tkgx8HgxBUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5FiQA2t/cTzmtG1sZ7i8vHV56nRLSyM7Rz9cTNv8bzG99G+mM8BG1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpkMx80S0bMkC/N+XGopc3roAAACYIEADAhKcAVVZWavr06UpNTVVWVpbmz5+vxsbGiH1Onz6t8vJyjR49WldeeaUWLlyotra2mA4NAEh8ngJUV1en8vJy7dq1S++99556eno0d+5cdXV1hfd54okn9M4772jTpk2qq6vT0aNHdd9998V8cABAYvP0IYTt27dHfF1dXa2srCw1NDRo1qxZ6ujo0K9+9Stt2LBBd999tyRp/fr1uuGGG7Rr1y7dfvvtsZscAJDQLuk9oI6ODklSRkaGJKmhoUE9PT0qLi4O7zN58mSNGzdO9fX1fX6P7u5uhUKhiA0AkPyiDlBvb69WrFihmTNnasqUKZKk1tZWpaSkKD09PWLf7Oxstba29vl9KisrFQgEwlteXl60IwEAEkjUASovL9eBAwe0cePGSxqgoqJCHR0d4a2lpeWSvh8AIDFE9YOoy5cv17Zt27Rz506NHTs2/HgwGNSZM2fU3t4ecRXU1tamYDDY5/fy+/3y+/3RjAEASGCeroCcc1q+fLk2b96sHTt2KD8/P+L5adOmafjw4aqpqQk/1tjYqMOHD6uoqCg2EwMAkoKnK6Dy8nJt2LBBW7duVWpqavh9nUAgoJEjRyoQCOiRRx7RypUrlZGRobS0ND3++OMqKiriE3AAgAieArR27VpJ0uzZsyMeX79+vZYsWSJJ+sUvfqEhQ4Zo4cKF6u7uVklJiX75y1/GZFgAQPLwFCDn3EX3GTFihKqqqlRVVRX1UABi5OL/yfapV72xnQPoA/eCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImo/kZUAImhd8TA3dX6i7PdA3YsJAeugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFEhivy1dF9W6T894v4npA9VPeV4zTh97XoPkwRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5ECSewnzf85qnVdv7za85px/86NReENV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgokszlHolp2haJbB3jBFRAAwAQBAgCY8BSgyspKTZ8+XampqcrKytL8+fPV2NgYsc/s2bPl8/kitsceeyymQwMAEp+nANXV1am8vFy7du3Se++9p56eHs2dO1ddXV0R+y1dulTHjh0Lb2vWrInp0ACAxOfpQwjbt2+P+Lq6ulpZWVlqaGjQrFmzwo+PGjVKwWAwNhMCAJLSJb0H1NHRIUnKyMiIePz1119XZmampkyZooqKCp06darf79Hd3a1QKBSxAQCSX9Qfw+7t7dWKFSs0c+ZMTZkyJfz4gw8+qPHjxys3N1f79+/X008/rcbGRr399tt9fp/KykqtXr062jEAAAnK55xz0SxctmyZfve73+nDDz/U2LFj+91vx44dmjNnjpqamjRx4sQLnu/u7lZ3d3f461AopLy8PM3WPA3zDY9mNACAoa9dj2q1VR0dHUpLS+t3v6iugJYvX65t27Zp586d3xofSSosLJSkfgPk9/vl9/ujGQMAkMA8Bcg5p8cff1ybN29WbW2t8vPzL7pm3759kqScnJyoBgQAJCdPASovL9eGDRu0detWpaamqrW1VZIUCAQ0cuRIHTp0SBs2bNA999yj0aNHa//+/XriiSc0a9YsTZ06NS7/AACAxOTpPSCfz9fn4+vXr9eSJUvU0tKi733vezpw4IC6urqUl5enBQsW6JlnnvnWPwf8e6FQSIFAgPeAACBBxeU9oIu1Ki8vT3V1dV6+JQDgMsW94AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJoZZD3A+55wk6Wv1SM54GACAZ1+rR9Lf/n/en0EXoM7OTknSh3rXeBIAwKXo7OxUIBDo93mfu1iiBlhvb6+OHj2q1NRU+Xy+iOdCoZDy8vLU0tKitLQ0owntcR7O4Tycw3k4h/NwzmA4D845dXZ2Kjc3V0OG9P9Oz6C7AhoyZIjGjh37rfukpaVd1i+wb3AezuE8nMN5OIfzcI71efi2K59v8CEEAIAJAgQAMJFQAfL7/Vq1apX8fr/1KKY4D+dwHs7hPJzDeTgnkc7DoPsQAgDg8pBQV0AAgORBgAAAJggQAMAEAQIAmEiYAFVVVemaa67RiBEjVFhYqD/84Q/WIw24559/Xj6fL2KbPHmy9Vhxt3PnTt17773Kzc2Vz+fTli1bIp53zum5555TTk6ORo4cqeLiYh08eNBm2Di62HlYsmTJBa+P0tJSm2HjpLKyUtOnT1dqaqqysrI0f/58NTY2Ruxz+vRplZeXa/To0bryyiu1cOFCtbW1GU0cH//IeZg9e/YFr4fHHnvMaOK+JUSA3nzzTa1cuVKrVq3SJ598ooKCApWUlOj48ePWow24m266SceOHQtvH374ofVIcdfV1aWCggJVVVX1+fyaNWv0yiuvaN26ddq9e7euuOIKlZSU6PTp0wM8aXxd7DxIUmlpacTr44033hjACeOvrq5O5eXl2rVrl9577z319PRo7ty56urqCu/zxBNP6J133tGmTZtUV1eno0eP6r777jOcOvb+kfMgSUuXLo14PaxZs8Zo4n64BDBjxgxXXl4e/vrs2bMuNzfXVVZWGk418FatWuUKCgqsxzAlyW3evDn8dW9vrwsGg+7FF18MP9be3u78fr974403DCYcGOefB+ecW7x4sZs3b57JPFaOHz/uJLm6ujrn3Ll/98OHD3ebNm0K7/Ppp586Sa6+vt5qzLg7/zw459x3vvMd94Mf/MBuqH/AoL8COnPmjBoaGlRcXBx+bMiQISouLlZ9fb3hZDYOHjyo3NxcTZgwQQ899JAOHz5sPZKp5uZmtba2Rrw+AoGACgsLL8vXR21trbKysjRp0iQtW7ZMJ06csB4prjo6OiRJGRkZkqSGhgb19PREvB4mT56scePGJfXr4fzz8I3XX39dmZmZmjJliioqKnTq1CmL8fo16G5Ger4vv/xSZ8+eVXZ2dsTj2dnZ+uyzz4ymslFYWKjq6mpNmjRJx44d0+rVq3XnnXfqwIEDSk1NtR7PRGtrqyT1+fr45rnLRWlpqe677z7l5+fr0KFD+vGPf6yysjLV19dr6NCh1uPFXG9vr1asWKGZM2dqypQpks69HlJSUpSenh6xbzK/Hvo6D5L04IMPavz48crNzdX+/fv19NNPq7GxUW+//bbhtJEGfYDwN2VlZeFfT506VYWFhRo/frzeeustPfLII4aTYTC4//77w7+++eabNXXqVE2cOFG1tbWaM2eO4WTxUV5ergMHDlwW74N+m/7Ow6OPPhr+9c0336ycnBzNmTNHhw4d0sSJEwd6zD4N+j+Cy8zM1NChQy/4FEtbW5uCwaDRVINDenq6rr/+ejU1NVmPYuab1wCvjwtNmDBBmZmZSfn6WL58ubZt26YPPvgg4q9vCQaDOnPmjNrb2yP2T9bXQ3/noS+FhYWSNKheD4M+QCkpKZo2bZpqamrCj/X29qqmpkZFRUWGk9k7efKkDh06pJycHOtRzOTn5ysYDEa8PkKhkHbv3n3Zvz6OHDmiEydOJNXrwzmn5cuXa/PmzdqxY4fy8/Mjnp82bZqGDx8e8XpobGzU4cOHk+r1cLHz0Jd9+/ZJ0uB6PVh/CuIfsXHjRuf3+111dbX74x//6B599FGXnp7uWltbrUcbUD/84Q9dbW2ta25udh999JErLi52mZmZ7vjx49ajxVVnZ6fbu3ev27t3r5PkXnrpJbd371735z//2Tnn3M9//nOXnp7utm7d6vbv3+/mzZvn8vPz3VdffWU8eWx923no7Ox0Tz75pKuvr3fNzc3u/fffd7feequ77rrr3OnTp61Hj5lly5a5QCDgamtr3bFjx8LbqVOnwvs89thjbty4cW7Hjh1uz549rqioyBUVFRlOHXsXOw9NTU3uJz/5iduzZ49rbm52W7dudRMmTHCzZs0ynjxSQgTIOedeffVVN27cOJeSkuJmzJjhdu3aZT3SgFu0aJHLyclxKSkp7uqrr3aLFi1yTU1N1mPF3QcffOAkXbAtXrzYOXfuo9jPPvusy87Odn6/382ZM8c1NjbaDh0H33YeTp065ebOnevGjBnjhg8f7saPH++WLl2adL9J6+ufX5Jbv359eJ+vvvrKff/733dXXXWVGzVqlFuwYIE7duyY3dBxcLHzcPjwYTdr1iyXkZHh/H6/u/baa92PfvQj19HRYTv4efjrGAAAJgb9e0AAgOREgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJj4fxRskeFospd0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data_tp1.csv',header=None)\n",
    "data = data.rename(columns={0:'y'})\n",
    "print(data.iloc[0,:].unique())\n",
    "\n",
    "imsize = round(np.sqrt(784)+1)\n",
    "linha_y = 4\n",
    "img = np.reshape(data.iloc[linha_y,1:].values, (imsize-1,imsize-1))\n",
    "plt.imshow(img)\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def data and model shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 784)\n",
      "(3350,)\n",
      "(784,)\n",
      "7\n",
      "Shape, type: X: torch.Size([25, 784]) torch.float32\n",
      "Shape, type: y: torch.Size([25]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data.y.values\n",
    "X = data.drop(columns='y').values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "idx = 0\n",
    "print((X_train[idx,:]).shape)\n",
    "print(y_train[idx])\n",
    "(y_train[idx]).shape \n",
    "\n",
    "# Pytorch exige que seja utilizado um dataset por algum motivo aparentemente\n",
    "class custom_mnist_dataset():\n",
    "    def __init__(self, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # RestriÃ§Ãµes de uso do pytorch: (leia os docs...)\n",
    "        # inputs tem que ser float para multiplicar pelos pesos, \n",
    "        # outputs tem que ser longint para calcular crossentropy \n",
    "        return torch.tensor(self.X[idx,:], dtype=torch.float), self.y[idx]\n",
    "\n",
    "training_data = custom_mnist_dataset(X = X_train, y = y_train)\n",
    "test_data = custom_mnist_dataset(X = X_test, y = y_test)\n",
    "\n",
    "# batch_size de exemplo para teste\n",
    "batch_size = 25\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape, type: X: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape, type: y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (entrada): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (oculta): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (saida): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "NeuralNetwork with  ...\n",
    "\"\"\"\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.entrada = nn.Linear(input_size, hidden_dim)\n",
    "        self.oculta = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.saida = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x1 = self.entrada(input)\n",
    "        x2 = F.sigmoid(self.oculta(x1))\n",
    "        x3 = self.saida(x2)\n",
    "\n",
    "        return x3\n",
    "    \n",
    "# hidden dim = 25,50,100\n",
    "print(NeuralNetwork(input_size = X_train.shape[1], hidden_dim= 25, output_size=10).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def train, test and eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/shrutimechlearn/pytorch-custom-model-step-by-step\n",
    "\n",
    "def train_step(model, loss_func, optimizer, dataloader):\n",
    "    \n",
    "    # to capture loss\n",
    "    train_loss = 0 \n",
    "\n",
    "    # to get the model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        # sending data to the device where rest of the artifacts are\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # forward pass/model prediction with the given input\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # loss calculation by comparison between predicted and ground truth values\n",
    "        loss = loss_func(y_pred, y_batch)\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "        # setting previously collected gradient values in the optimizer to zero so it translates only current gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate the gradients for this iteration (independent gradients because previous values have been reset to 0)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights and biases based on the calculated gradients ~(wi = wi + delta_wi)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, loss_func, test_dataloader):\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for batch, (x_batch, y_batch) in enumerate(test_dataloader):\n",
    "            \n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            loss = loss_func(y_pred, y_batch)\n",
    "            test_loss+= loss.item()\n",
    "\n",
    "    test_loss = test_loss/len(test_dataloader)   \n",
    "\n",
    "    return test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch import optim\n",
    "\n",
    "def eval_step_with_mlflowlogging(model,test_dataloader):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_preds = []\n",
    "        total_labels = []\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(total_labels, total_preds)\n",
    "    precision = precision_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    recall = recall_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def train_with_mlflowlogging(model, loss_func, optimizer, train_dataloader, test_dataloader, n_epochs, i,lr,hds,bs):\n",
    "    with mlflow.start_run(run_name=f\"Test #{i} - lr({lr}) hds({hds}) bs({bs})\", nested = True):  # Name each run based on the learning rate\n",
    "        mlflow.log_param(\"batch_size\", bs)\n",
    "        mlflow.log_param(\"hidden_dim\", hds)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        \n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "    \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            tr_loss = train_step(model, loss_func, optimizer, train_dataloader)\n",
    "            train_loss.append(tr_loss)\n",
    "        \n",
    "            ts_loss = test_step(model, loss_func, test_dataloader)\n",
    "            test_loss.append(ts_loss)    \n",
    "\n",
    "            accuracy, precision, recall, f1 = eval_step_with_mlflowlogging(model, test_dataloader)\n",
    "            \n",
    "            mlflow.log_metric(\"loss\", tr_loss, step = epoch)\n",
    "            mlflow.log_metric(\"val_loss\", ts_loss, step = epoch)\n",
    "            mlflow.log_metric(\"diff_loss_tr_ts\", tr_loss-ts_loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"loss\", tr_loss, step = epoch)\n",
    "            mlflow.log_metric(\"val_loss\", ts_loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"accuracy\", accuracy, step = epoch)\n",
    "            mlflow.log_metric(\"precision\", precision, step = epoch)\n",
    "            mlflow.log_metric(\"recall\", recall, step = epoch)\n",
    "            mlflow.log_metric(\"f1\", f1, step = epoch)   \n",
    "\n",
    "    return train_loss, test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def automated trials and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import torch.optim as optim\n",
    "\n",
    "\n",
    "# # Assuming the rest of your imports and setup code remains the same\n",
    "\n",
    "# def objective(trial, lr, hds, bs):\n",
    "#     # Suggest regularization parameter using the trial object\n",
    "#     weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n",
    "    \n",
    "#     # Initialize the model with fixed hyperparameters and suggested regularization\n",
    "#     model = NeuralNetwork(input_size=X_train.shape[1], hidden_dim=hds, output_size=10).to(device)\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "#     # Training and evaluation steps remain the same, just ensure they use the model, loss_func, and optimizer initialized above\n",
    "#     # Note: You might need to adjust the train_with_mlflowlogging function to remove mlflow logging since we're focusing on Optuna integration now\n",
    "#     loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     # Example of how you might structure the training and evaluation inside the objective function\n",
    "#     for epoch in range(5):  # Number of epochs\n",
    "#         train_loss = train_step(model, loss_func, optimizer, train_dataloader)\n",
    "#         test_loss = test_step(model, loss_func, test_dataloader)\n",
    "#         # Evaluate other metrics as needed\n",
    "\n",
    "#     # Return a value that Optuna will try to minimize/maximize. For example, you could return the negative mean test loss\n",
    "#     return test_loss\n",
    "\n",
    "# # Fixed hyperparameters\n",
    "# fixed_hyperparams = {\n",
    "#     'learning_rates': [0.5, 1, 10],\n",
    "#     'hidden_dim_sizes': [25, 50, 100],\n",
    "#     'batch_sizes': [1, 10, 50, len(training_data)],\n",
    "# }\n",
    "\n",
    "\n",
    "# # Iterate over fixed hyperparameters\n",
    "# best_results = {}\n",
    "# for lr in fixed_hyperparams['learning_rates']:\n",
    "#     for hds in fixed_hyperparams['hidden_dim_sizes']:\n",
    "#         for bs in fixed_hyperparams['batch_sizes']:\n",
    "#             # Create an Optuna study for each combination\n",
    "#             study = optuna.create_study(direction='minimize')\n",
    "#             study.optimize(lambda t: objective(t, lr, hds, bs), n_trials=10)  # Adjust n_trials as needed\n",
    "            \n",
    "#             # Record the best trial\n",
    "#             best_trial = study.best_trial\n",
    "#             best_weight_decay = best_trial.params['weight_decay']\n",
    "#             best_test_loss = best_trial.value\n",
    "            \n",
    "#             # Record best results\n",
    "#             best_results[(lr, hds, bs)] = {\n",
    "#                 'weight_decay': best_weight_decay,\n",
    "#                 'test_loss': best_test_loss,\n",
    "#             }\n",
    "\n",
    "# # Print the best results\n",
    "# for (lr, hds, bs), result in best_results.items():\n",
    "#     print(f\"Learning Rate: {lr}, Hidden Dimension Size: {hds}, Batch Size: {bs}\")\n",
    "#     print(f\"Best Weight Decay: {result['weight_decay']}, Test Loss: {result['test_loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/14 17:14:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2024/06/14 17:14:00 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240614T171400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/14 17:14:02 INFO mlflow.tracking.fluent: Experiment with name 'TP1ML - 20240614T171400' does not exist. Creating a new experiment.\n",
      "[I 2024-06-14 17:14:02,746] A new study created in memory with name: Study - lr(0.5) hds(25) bs(1) - 20240614T171400\n",
      "[I 2024-06-14 17:28:57,715] Trial 0 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.21959577383015977}. \n",
      "[I 2024-06-14 17:43:25,827] Trial 1 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.21500514532677525}. \n",
      "[I 2024-06-14 17:54:25,419] Trial 2 finished with values: [0.184, 0.184] and parameters: {'weight_decay': 0.44257706530185137}. \n",
      "[I 2024-06-14 18:05:01,077] Trial 3 finished with values: [0.196, 0.196] and parameters: {'weight_decay': 0.09553956957123408}. \n",
      "[I 2024-06-14 18:15:35,535] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.19098081093234126}. \n",
      "[I 2024-06-14 18:15:35,535] A new study created in memory with name: Study - lr(0.5) hds(25) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 18:18:26,044] Trial 0 finished with values: [0.09519999999999999, 0.1715932178932179] and parameters: {'weight_decay': 0.6449586195840052}. \n",
      "[I 2024-06-14 18:21:16,838] Trial 1 finished with values: [0.09839999999999999, 0.17085873015873015] and parameters: {'weight_decay': 0.49536770948002895}. \n",
      "[I 2024-06-14 18:24:09,967] Trial 2 finished with values: [0.12959999999999997, 0.25057840492840494] and parameters: {'weight_decay': 0.08863935515479908}. \n",
      "[I 2024-06-14 18:26:59,544] Trial 3 finished with values: [0.09319999999999999, 0.16461659451659452] and parameters: {'weight_decay': 0.7196140365157762}. \n",
      "[I 2024-06-14 18:29:50,905] Trial 4 finished with values: [0.09759999999999999, 0.17128725718725718] and parameters: {'weight_decay': 0.9510594235615238}. \n",
      "[I 2024-06-14 18:29:50,905] A new study created in memory with name: Study - lr(0.5) hds(25) bs(50) - 20240614T171400\n",
      "[I 2024-06-14 18:31:10,881] Trial 0 finished with values: [0.115, 0.21632394500391] and parameters: {'weight_decay': 0.4371160126247986}. \n",
      "[I 2024-06-14 18:32:31,349] Trial 1 finished with values: [0.1, 0.18067340504187468] and parameters: {'weight_decay': 0.5641343171601241}. \n",
      "[I 2024-06-14 18:33:50,984] Trial 2 finished with values: [0.109, 0.20000850169858903] and parameters: {'weight_decay': 0.467403276703812}. \n",
      "[I 2024-06-14 18:35:12,378] Trial 3 finished with values: [0.14220000000000002, 0.27226573980385704] and parameters: {'weight_decay': 0.28750732902784804}. \n",
      "[I 2024-06-14 18:36:33,088] Trial 4 finished with values: [0.1144, 0.20355822567253204] and parameters: {'weight_decay': 0.5128587122131456}. \n",
      "[I 2024-06-14 18:36:33,088] A new study created in memory with name: Study - lr(0.5) hds(25) bs(3350) - 20240614T171400\n",
      "[I 2024-06-14 18:37:29,648] Trial 0 finished with values: [0.12644776119402984, 0.20268156137405935] and parameters: {'weight_decay': 0.8625256787803871}. \n",
      "[I 2024-06-14 18:38:26,640] Trial 1 finished with values: [0.21567164179104478, 0.2872489935902312] and parameters: {'weight_decay': 0.2808686595599838}. \n",
      "[I 2024-06-14 18:39:23,349] Trial 2 finished with values: [0.1466686567164179, 0.22996352341938392] and parameters: {'weight_decay': 0.6410861306586343}. \n",
      "[I 2024-06-14 18:40:19,741] Trial 3 finished with values: [0.126644776119403, 0.20694491339749044] and parameters: {'weight_decay': 0.9660376767249336}. \n",
      "[I 2024-06-14 18:41:16,850] Trial 4 finished with values: [0.15186865671641792, 0.22976659877162234] and parameters: {'weight_decay': 0.5817183652027756}. \n",
      "[I 2024-06-14 18:41:16,850] A new study created in memory with name: Study - lr(0.5) hds(50) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.12644776119402984, 'best_f1': 0.20268156137405935}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 19:00:25,195] Trial 0 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.5446390218350867}. \n",
      "[I 2024-06-14 19:19:26,624] Trial 1 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.4552508560835999}. \n",
      "[I 2024-06-14 19:38:36,799] Trial 2 finished with values: [0.176, 0.176] and parameters: {'weight_decay': 0.778494863828787}. \n",
      "[I 2024-06-14 19:57:15,756] Trial 3 finished with values: [0.204, 0.204] and parameters: {'weight_decay': 0.0015404607994889024}. \n",
      "[I 2024-06-14 20:16:21,536] Trial 4 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.4629116463610798}. \n",
      "[I 2024-06-14 20:16:21,536] A new study created in memory with name: Study - lr(0.5) hds(50) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 20:19:19,133] Trial 0 finished with values: [0.09919999999999998, 0.17404293114293115] and parameters: {'weight_decay': 0.7830846297624006}. \n",
      "[I 2024-06-14 20:22:15,931] Trial 1 finished with values: [0.10119999999999998, 0.1758089244089244] and parameters: {'weight_decay': 0.553521745444784}. \n",
      "[I 2024-06-14 20:25:13,097] Trial 2 finished with values: [0.10599999999999998, 0.18637210197210197] and parameters: {'weight_decay': 0.24088230578302533}. \n",
      "[I 2024-06-14 20:28:09,912] Trial 3 finished with values: [0.09879999999999999, 0.17491002886002885] and parameters: {'weight_decay': 0.4039562992473984}. \n",
      "[I 2024-06-14 20:31:06,494] Trial 4 finished with values: [0.09519999999999999, 0.16834254634254633] and parameters: {'weight_decay': 0.49551030726824047}. \n",
      "[I 2024-06-14 20:31:06,494] A new study created in memory with name: Study - lr(0.5) hds(50) bs(50) - 20240614T171400\n",
      "[I 2024-06-14 20:32:30,911] Trial 0 finished with values: [0.0922, 0.16189633687505506] and parameters: {'weight_decay': 0.73364910869754}. \n",
      "[I 2024-06-14 20:33:53,461] Trial 1 finished with values: [0.11259999999999999, 0.22460881981143985] and parameters: {'weight_decay': 0.2461853596047678}. \n",
      "[I 2024-06-14 20:35:19,302] Trial 2 finished with values: [0.0968, 0.17859026488161636] and parameters: {'weight_decay': 0.5799001219339466}. \n",
      "[I 2024-06-14 20:36:41,561] Trial 3 finished with values: [0.09820000000000002, 0.17575017999718634] and parameters: {'weight_decay': 0.43262493283491316}. \n",
      "[I 2024-06-14 20:38:04,230] Trial 4 finished with values: [0.0968, 0.17327312323193564] and parameters: {'weight_decay': 0.6260976010715901}. \n",
      "[I 2024-06-14 20:38:04,230] A new study created in memory with name: Study - lr(0.5) hds(50) bs(3350) - 20240614T171400\n",
      "[I 2024-06-14 20:39:02,634] Trial 0 finished with values: [0.13822089552238806, 0.21794346373458615] and parameters: {'weight_decay': 0.5098284441073947}. \n",
      "[I 2024-06-14 20:40:01,291] Trial 1 finished with values: [0.12711044776119404, 0.21055531854360235] and parameters: {'weight_decay': 0.7683195687674663}. \n",
      "[I 2024-06-14 20:41:00,677] Trial 2 finished with values: [0.650841791044776, 0.6344454413901801] and parameters: {'weight_decay': 0.04467063279199616}. \n",
      "[I 2024-06-14 20:42:00,315] Trial 3 finished with values: [0.13413134328358212, 0.211405553851293] and parameters: {'weight_decay': 0.6323327995417789}. \n",
      "[I 2024-06-14 20:42:58,954] Trial 4 finished with values: [0.15983880597014924, 0.24375670803620972] and parameters: {'weight_decay': 0.5069297697321665}. \n",
      "[I 2024-06-14 20:42:58,954] A new study created in memory with name: Study - lr(0.5) hds(100) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.12711044776119404, 'best_f1': 0.21055531854360235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 21:03:31,545] Trial 0 finished with values: [0.184, 0.184] and parameters: {'weight_decay': 0.47037452419065745}. \n",
      "[I 2024-06-14 21:24:08,968] Trial 1 finished with values: [0.176, 0.176] and parameters: {'weight_decay': 0.7996287629957927}. \n",
      "[I 2024-06-14 21:44:35,693] Trial 2 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.3925602124016348}. \n",
      "[I 2024-06-14 22:04:51,970] Trial 3 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.12113575838280395}. \n",
      "[I 2024-06-14 22:25:27,193] Trial 4 finished with values: [0.18, 0.18] and parameters: {'weight_decay': 0.552613136185498}. \n",
      "[I 2024-06-14 22:25:27,193] A new study created in memory with name: Study - lr(0.5) hds(100) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 22:28:42,422] Trial 0 finished with values: [0.1148, 0.2119708791208791] and parameters: {'weight_decay': 0.09189964249114192}. \n",
      "[I 2024-06-14 22:31:53,717] Trial 1 finished with values: [0.10079999999999999, 0.1746550937950938] and parameters: {'weight_decay': 0.4548363964926019}. \n",
      "[I 2024-06-14 22:35:04,798] Trial 2 finished with values: [0.1, 0.17578826358826358] and parameters: {'weight_decay': 0.45459303443108856}. \n",
      "[I 2024-06-14 22:38:22,341] Trial 3 finished with values: [0.10119999999999998, 0.17825769785769785] and parameters: {'weight_decay': 0.2966864913798706}. \n",
      "[I 2024-06-14 22:41:35,220] Trial 4 finished with values: [0.09799999999999999, 0.16887715617715618] and parameters: {'weight_decay': 0.23529681481631629}. \n",
      "[I 2024-06-14 22:41:35,220] A new study created in memory with name: Study - lr(0.5) hds(100) bs(50) - 20240614T171400\n",
      "[I 2024-06-14 22:43:04,219] Trial 0 finished with values: [0.0892, 0.162796056832086] and parameters: {'weight_decay': 0.4120038398442698}. \n",
      "[I 2024-06-14 22:44:38,136] Trial 1 finished with values: [0.09, 0.16325570989137558] and parameters: {'weight_decay': 0.7334293012069532}. \n",
      "[I 2024-06-14 22:46:10,516] Trial 2 finished with values: [0.09880000000000001, 0.19291702159136614] and parameters: {'weight_decay': 0.16509905000598027}. \n",
      "[I 2024-06-14 22:47:40,565] Trial 3 finished with values: [0.0882, 0.15039467412119048] and parameters: {'weight_decay': 0.813824328060253}. \n",
      "[I 2024-06-14 22:49:10,240] Trial 4 finished with values: [0.09160000000000001, 0.16294464791496427] and parameters: {'weight_decay': 0.8806112542634088}. \n",
      "[I 2024-06-14 22:49:10,242] A new study created in memory with name: Study - lr(0.5) hds(100) bs(3350) - 20240614T171400\n",
      "[I 2024-06-14 22:50:13,468] Trial 0 finished with values: [0.11767164179104478, 0.19732679397846556] and parameters: {'weight_decay': 0.8893168974793102}. \n",
      "[I 2024-06-14 22:51:16,889] Trial 1 finished with values: [0.13170149253731345, 0.20960435470118607] and parameters: {'weight_decay': 0.6254512958647336}. \n",
      "[I 2024-06-14 22:52:20,376] Trial 2 finished with values: [0.11764776119402984, 0.19075030429565287] and parameters: {'weight_decay': 0.7942889368688288}. \n",
      "[I 2024-06-14 22:53:23,231] Trial 3 finished with values: [0.14002985074626867, 0.22047065458240225] and parameters: {'weight_decay': 0.443751498557575}. \n",
      "[I 2024-06-14 22:54:25,750] Trial 4 finished with values: [0.12125970149253731, 0.19505548278482912] and parameters: {'weight_decay': 0.8328219535143311}. \n",
      "[I 2024-06-14 22:54:25,752] A new study created in memory with name: Study - lr(1) hds(25) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.11764776119402984, 'best_f1': 0.19075030429565287}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 23:04:09,870] Trial 0 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.8077541123941098}. \n",
      "[I 2024-06-14 23:13:52,157] Trial 1 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.8911956487986815}. \n",
      "[I 2024-06-14 23:23:37,542] Trial 2 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.9287766725951332}. \n",
      "[I 2024-06-14 23:33:48,954] Trial 3 finished with values: [0.196, 0.196] and parameters: {'weight_decay': 0.08787365325399454}. \n",
      "[I 2024-06-14 23:44:15,680] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.028488046939587255}. \n",
      "[I 2024-06-14 23:44:15,680] A new study created in memory with name: Study - lr(1) hds(25) bs(10) - 20240614T171400\n",
      "[I 2024-06-14 23:47:25,359] Trial 0 finished with values: [0.10119999999999998, 0.17892701002701006] and parameters: {'weight_decay': 0.48873330745605587}. \n",
      "[I 2024-06-14 23:50:31,307] Trial 1 finished with values: [0.098, 0.17355656565656566] and parameters: {'weight_decay': 0.34565641267523645}. \n",
      "[I 2024-06-14 23:53:18,906] Trial 2 finished with values: [0.09999999999999999, 0.175390934990935] and parameters: {'weight_decay': 0.500565983244663}. \n",
      "[I 2024-06-14 23:56:06,973] Trial 3 finished with values: [0.09999999999999999, 0.17575757575757575] and parameters: {'weight_decay': 0.956060042136712}. \n",
      "[I 2024-06-14 23:58:56,007] Trial 4 finished with values: [0.1008, 0.17773648573648576] and parameters: {'weight_decay': 0.786298019975178}. \n",
      "[I 2024-06-14 23:58:56,007] A new study created in memory with name: Study - lr(1) hds(25) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 00:00:23,723] Trial 0 finished with values: [0.1214, 0.25510200888769213] and parameters: {'weight_decay': 0.09256887090109078}. \n",
      "[I 2024-06-15 00:01:44,307] Trial 1 finished with values: [0.0722, 0.1297412521917442] and parameters: {'weight_decay': 0.61345496510177}. \n",
      "[I 2024-06-15 00:03:06,493] Trial 2 finished with values: [0.07680000000000001, 0.1370479954827781] and parameters: {'weight_decay': 0.940399211296342}. \n",
      "[I 2024-06-15 00:04:32,059] Trial 3 finished with values: [0.088, 0.16583643353876698] and parameters: {'weight_decay': 0.22000916028122283}. \n",
      "[I 2024-06-15 00:05:53,776] Trial 4 finished with values: [0.0692, 0.12239022461990831] and parameters: {'weight_decay': 0.6463253694901357}. \n",
      "[I 2024-06-15 00:05:53,777] A new study created in memory with name: Study - lr(1) hds(25) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 00:06:54,382] Trial 0 finished with values: [0.1419761194029851, 0.22808727233022888] and parameters: {'weight_decay': 0.23618038042214715}. \n",
      "[I 2024-06-15 00:07:54,920] Trial 1 finished with values: [0.11386865671641791, 0.19592595636178156] and parameters: {'weight_decay': 0.8478868598568371}. \n",
      "[I 2024-06-15 00:08:55,760] Trial 2 finished with values: [0.12284179104477612, 0.20706804361098763] and parameters: {'weight_decay': 0.6388473550580727}. \n",
      "[I 2024-06-15 00:09:56,927] Trial 3 finished with values: [0.12433432835820897, 0.21499166053022703] and parameters: {'weight_decay': 0.5312672345130159}. \n",
      "[I 2024-06-15 00:10:57,723] Trial 4 finished with values: [0.11536716417910448, 0.2005148646451018] and parameters: {'weight_decay': 0.9569397817320676}. \n",
      "[I 2024-06-15 00:10:57,724] A new study created in memory with name: Study - lr(1) hds(50) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.11386865671641791, 'best_f1': 0.19592595636178156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 00:28:53,936] Trial 0 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.43319070458962194}. \n",
      "[I 2024-06-15 00:46:49,282] Trial 1 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.36149240461487325}. \n",
      "[I 2024-06-15 01:03:51,873] Trial 2 finished with values: [0.196, 0.196] and parameters: {'weight_decay': 0.6142344864190896}. \n",
      "[I 2024-06-15 01:21:34,084] Trial 3 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.10759361402933605}. \n",
      "[I 2024-06-15 01:38:35,613] Trial 4 finished with values: [0.18, 0.18] and parameters: {'weight_decay': 0.523187461382211}. \n",
      "[I 2024-06-15 01:38:35,613] A new study created in memory with name: Study - lr(1) hds(50) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 01:41:35,861] Trial 0 finished with values: [0.10879999999999998, 0.19225087135087138] and parameters: {'weight_decay': 0.036662862954002486}. \n",
      "[I 2024-06-15 01:44:35,409] Trial 1 finished with values: [0.11760000000000001, 0.2146398727198727] and parameters: {'weight_decay': 0.014970211254698848}. \n",
      "[I 2024-06-15 01:47:28,428] Trial 2 finished with values: [0.09759999999999999, 0.17195870795870796] and parameters: {'weight_decay': 0.9003063287212307}. \n",
      "[I 2024-06-15 01:50:26,124] Trial 3 finished with values: [0.10119999999999998, 0.17699989121989124] and parameters: {'weight_decay': 0.28091651808737145}. \n",
      "[I 2024-06-15 01:53:17,689] Trial 4 finished with values: [0.09919999999999998, 0.1754768897768898] and parameters: {'weight_decay': 0.6796657484753943}. \n",
      "[I 2024-06-15 01:53:17,689] A new study created in memory with name: Study - lr(1) hds(50) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 01:54:44,572] Trial 0 finished with values: [0.078, 0.14489336382394158] and parameters: {'weight_decay': 0.2561813020669501}. \n",
      "[I 2024-06-15 01:56:11,591] Trial 1 finished with values: [0.07479999999999999, 0.13315134067051687] and parameters: {'weight_decay': 0.8642617326758352}. \n",
      "[I 2024-06-15 01:57:41,304] Trial 2 finished with values: [0.082, 0.15239711033702857] and parameters: {'weight_decay': 0.15554326475510075}. \n",
      "[I 2024-06-15 01:59:10,173] Trial 3 finished with values: [0.07180000000000002, 0.12847061890822023] and parameters: {'weight_decay': 0.4195926330379432}. \n",
      "[I 2024-06-15 02:00:38,555] Trial 4 finished with values: [0.0758, 0.13632719568969942] and parameters: {'weight_decay': 0.3754229723139094}. \n",
      "[I 2024-06-15 02:00:38,555] A new study created in memory with name: Study - lr(1) hds(50) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 02:01:41,225] Trial 0 finished with values: [0.11530149253731344, 0.1955192444341067] and parameters: {'weight_decay': 0.5970874561572252}. \n",
      "[I 2024-06-15 02:02:44,778] Trial 1 finished with values: [0.36514029850746266, 0.36242994730283284] and parameters: {'weight_decay': 0.05466484635305201}. \n",
      "[I 2024-06-15 02:03:48,349] Trial 2 finished with values: [0.11907462686567165, 0.19480953133148823] and parameters: {'weight_decay': 0.2893438867984909}. \n",
      "[I 2024-06-15 02:04:51,571] Trial 3 finished with values: [0.1204955223880597, 0.19940340111035487] and parameters: {'weight_decay': 0.38854890017036336}. \n",
      "[I 2024-06-15 02:05:54,907] Trial 4 finished with values: [0.11682985074626866, 0.1940043358949208] and parameters: {'weight_decay': 0.6035059176739791}. \n",
      "[I 2024-06-15 02:05:54,907] A new study created in memory with name: Study - lr(1) hds(100) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.11530149253731344, 'best_f1': 0.1955192444341067}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 02:23:51,862] Trial 0 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.9715069529194521}. \n",
      "[I 2024-06-15 02:41:48,567] Trial 1 finished with values: [0.192, 0.192] and parameters: {'weight_decay': 0.78589074845382}. \n",
      "[I 2024-06-15 03:01:01,906] Trial 2 finished with values: [0.188, 0.188] and parameters: {'weight_decay': 0.41956517210792976}. \n",
      "[I 2024-06-15 03:18:59,344] Trial 3 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.8452990388166546}. \n",
      "[I 2024-06-15 03:36:54,985] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.6592282579658413}. \n",
      "[I 2024-06-15 03:36:54,985] A new study created in memory with name: Study - lr(1) hds(100) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 03:40:01,106] Trial 0 finished with values: [0.09839999999999997, 0.17169175084175084] and parameters: {'weight_decay': 0.7229758223449322}. \n",
      "[I 2024-06-15 03:43:15,125] Trial 1 finished with values: [0.09799999999999999, 0.17388724941724945] and parameters: {'weight_decay': 0.49652837111178894}. \n",
      "[I 2024-06-15 03:46:20,738] Trial 2 finished with values: [0.0996, 0.17472302142302146] and parameters: {'weight_decay': 0.5819402185600685}. \n",
      "[I 2024-06-15 03:49:22,568] Trial 3 finished with values: [0.10239999999999999, 0.17888706848706848] and parameters: {'weight_decay': 0.8648761879858713}. \n",
      "[I 2024-06-15 03:52:26,399] Trial 4 finished with values: [0.1024, 0.1789069597069597] and parameters: {'weight_decay': 0.8003784868145967}. \n",
      "[I 2024-06-15 03:52:26,399] A new study created in memory with name: Study - lr(1) hds(100) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 03:53:57,531] Trial 0 finished with values: [0.0698, 0.12343093042223478] and parameters: {'weight_decay': 0.9682414591499549}. \n",
      "[I 2024-06-15 03:55:37,030] Trial 1 finished with values: [0.0824, 0.1495506988606733] and parameters: {'weight_decay': 0.33138249695087185}. \n",
      "[I 2024-06-15 03:57:19,861] Trial 2 finished with values: [0.09919999999999998, 0.19441103503607957] and parameters: {'weight_decay': 0.067873348509183}. \n",
      "[I 2024-06-15 03:58:54,976] Trial 3 finished with values: [0.084, 0.14688287499344863] and parameters: {'weight_decay': 0.44231194824531467}. \n",
      "[I 2024-06-15 04:00:35,436] Trial 4 finished with values: [0.079, 0.14027568000464602] and parameters: {'weight_decay': 0.32585734298718044}. \n",
      "[I 2024-06-15 04:00:35,436] A new study created in memory with name: Study - lr(1) hds(100) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 04:01:41,625] Trial 0 finished with values: [0.11038208955223883, 0.18908622916427317] and parameters: {'weight_decay': 0.703336085654078}. \n",
      "[I 2024-06-15 04:02:49,213] Trial 1 finished with values: [0.12429850746268656, 0.21314249550683761] and parameters: {'weight_decay': 0.2332278806247643}. \n",
      "[I 2024-06-15 04:03:56,147] Trial 2 finished with values: [0.11155820895522388, 0.18825560511162115] and parameters: {'weight_decay': 0.648316911405224}. \n",
      "[I 2024-06-15 04:05:04,383] Trial 3 finished with values: [0.1092179104477612, 0.18565819725180752] and parameters: {'weight_decay': 0.6101215697724652}. \n",
      "[I 2024-06-15 04:06:14,253] Trial 4 finished with values: [0.10873432835820895, 0.1941751753254041] and parameters: {'weight_decay': 0.9273425510931056}. \n",
      "[I 2024-06-15 04:06:14,253] A new study created in memory with name: Study - lr(10) hds(25) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.1092179104477612, 'best_f1': 0.18565819725180752}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 04:15:43,390] Trial 0 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.8153151002896245}. \n",
      "[I 2024-06-15 04:25:15,845] Trial 1 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.948927162147763}. \n",
      "[I 2024-06-15 04:34:39,534] Trial 2 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.7234808057757657}. \n",
      "[I 2024-06-15 04:44:05,589] Trial 3 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.6993623573611013}. \n",
      "[I 2024-06-15 04:53:33,130] Trial 4 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.3034188447206517}. \n",
      "[I 2024-06-15 04:53:33,130] A new study created in memory with name: Study - lr(10) hds(25) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 04:56:19,228] Trial 0 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9588507205556946}. \n",
      "[I 2024-06-15 04:59:03,146] Trial 1 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.3522450444911105}. \n",
      "[I 2024-06-15 05:01:49,928] Trial 2 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9755578230826403}. \n",
      "[I 2024-06-15 05:04:37,280] Trial 3 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.3957974705607464}. \n",
      "[I 2024-06-15 05:07:27,747] Trial 4 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.5272530632898731}. \n",
      "[I 2024-06-15 05:07:27,747] A new study created in memory with name: Study - lr(10) hds(25) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 05:08:51,064] Trial 0 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.9797993959223117}. \n",
      "[I 2024-06-15 05:10:18,746] Trial 1 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.21876524939082392}. \n",
      "[I 2024-06-15 05:11:43,946] Trial 2 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.35316310662527245}. \n",
      "[I 2024-06-15 05:13:16,628] Trial 3 finished with values: [0.07, 0.12663278750235274] and parameters: {'weight_decay': 0.13221285182383274}. \n",
      "[I 2024-06-15 05:14:42,181] Trial 4 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.35672646010386955}. \n",
      "[I 2024-06-15 05:14:42,181] A new study created in memory with name: Study - lr(10) hds(25) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 05:15:47,318] Trial 0 finished with values: [0.10754626865671642, 0.18878246304692892] and parameters: {'weight_decay': 0.07436721195324679}. \n",
      "[I 2024-06-15 05:16:52,986] Trial 1 finished with values: [0.10383880597014926, 0.18285509869009578] and parameters: {'weight_decay': 0.01691536455375388}. \n",
      "[I 2024-06-15 05:17:58,690] Trial 2 finished with values: [0.10554029850746269, 0.18477119119768778] and parameters: {'weight_decay': 0.01769727713179969}. \n",
      "[I 2024-06-15 05:19:03,187] Trial 3 finished with values: [0.09521791044776119, 0.16838521032625464] and parameters: {'weight_decay': 0.9160756001709291}. \n",
      "[I 2024-06-15 05:20:10,664] Trial 4 finished with values: [0.0939582089552239, 0.17174139689535695] and parameters: {'weight_decay': 0.6584390041817857}. \n",
      "[I 2024-06-15 05:20:10,664] A new study created in memory with name: Study - lr(10) hds(50) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.09521791044776119, 'best_f1': 0.16838521032625464}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 05:37:00,748] Trial 0 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.5983167038913301}. \n",
      "[I 2024-06-15 05:53:57,898] Trial 1 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.8530436350201308}. \n",
      "[I 2024-06-15 06:12:08,692] Trial 2 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.033576507924941316}. \n",
      "[I 2024-06-15 06:30:30,320] Trial 3 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.07502623203456486}. \n",
      "[I 2024-06-15 06:49:02,280] Trial 4 finished with values: [0.2, 0.2] and parameters: {'weight_decay': 0.0900948638506418}. \n",
      "[I 2024-06-15 06:49:02,280] A new study created in memory with name: Study - lr(10) hds(50) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 06:52:18,459] Trial 0 finished with values: [0.10119999999999998, 0.17154312354312357] and parameters: {'weight_decay': 0.12814785837400428}. \n",
      "[I 2024-06-15 06:55:11,191] Trial 1 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9243009741278334}. \n",
      "[I 2024-06-15 06:58:03,474] Trial 2 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.8157005057525126}. \n",
      "[I 2024-06-15 07:00:56,590] Trial 3 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.8904752494379335}. \n",
      "[I 2024-06-15 07:04:00,270] Trial 4 finished with values: [0.09919999999999998, 0.17333102453102453] and parameters: {'weight_decay': 0.06094815539532095}. \n",
      "[I 2024-06-15 07:04:00,270] A new study created in memory with name: Study - lr(10) hds(50) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 07:05:33,740] Trial 0 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.7081917289164852}. \n",
      "[I 2024-06-15 07:07:00,510] Trial 1 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.943459483629794}. \n",
      "[I 2024-06-15 07:08:32,967] Trial 2 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.4901724387745128}. \n",
      "[I 2024-06-15 07:10:00,369] Trial 3 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.36495960569082186}. \n",
      "[I 2024-06-15 07:11:36,581] Trial 4 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.19331924891050403}. \n",
      "[I 2024-06-15 07:11:36,581] A new study created in memory with name: Study - lr(10) hds(50) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 07:12:42,568] Trial 0 finished with values: [0.09560597014925375, 0.17409795795781877] and parameters: {'weight_decay': 0.6653931191440079}. \n",
      "[I 2024-06-15 07:13:48,405] Trial 1 finished with values: [0.0941492537313433, 0.16941141544823762] and parameters: {'weight_decay': 0.9149889235337078}. \n",
      "[I 2024-06-15 07:14:54,825] Trial 2 finished with values: [0.09520000000000002, 0.17345821199454164] and parameters: {'weight_decay': 0.9793230741048037}. \n",
      "[I 2024-06-15 07:16:01,265] Trial 3 finished with values: [0.09525373134328359, 0.17350442715393616] and parameters: {'weight_decay': 0.6816412509081851}. \n",
      "[I 2024-06-15 07:17:12,598] Trial 4 finished with values: [0.10674626865671642, 0.1805587790586577] and parameters: {'weight_decay': 0.01176490228244394}. \n",
      "[I 2024-06-15 07:17:12,598] A new study created in memory with name: Study - lr(10) hds(100) bs(1) - 20240614T171400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.0941492537313433, 'best_f1': 0.16941141544823762}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 07:34:42,608] Trial 0 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.32985694591643283}. \n",
      "[I 2024-06-15 07:52:11,984] Trial 1 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.47150346490262296}. \n",
      "[I 2024-06-15 08:09:45,976] Trial 2 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.9262503398897733}. \n",
      "[I 2024-06-15 08:27:14,987] Trial 3 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.6928725788725207}. \n",
      "[I 2024-06-15 08:44:40,724] Trial 4 finished with values: [0.0, 0.0] and parameters: {'weight_decay': 0.7535128077498956}. \n",
      "[I 2024-06-15 08:44:40,725] A new study created in memory with name: Study - lr(10) hds(100) bs(10) - 20240614T171400\n",
      "[I 2024-06-15 08:47:43,129] Trial 0 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.9757882840054308}. \n",
      "[I 2024-06-15 08:51:01,575] Trial 1 finished with values: [0.10039999999999998, 0.177359595959596] and parameters: {'weight_decay': 0.07295314640314535}. \n",
      "[I 2024-06-15 08:54:24,786] Trial 2 finished with values: [0.1044, 0.18138192474192477] and parameters: {'weight_decay': 0.026643986907717538}. \n",
      "[I 2024-06-15 08:57:27,031] Trial 3 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.5176794343725942}. \n",
      "[I 2024-06-15 09:00:28,196] Trial 4 finished with values: [0.04, 0.07272727272727274] and parameters: {'weight_decay': 0.325232402007046}. \n",
      "[I 2024-06-15 09:00:28,196] A new study created in memory with name: Study - lr(10) hds(100) bs(50) - 20240614T171400\n",
      "[I 2024-06-15 09:01:59,113] Trial 0 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.45996678833514826}. \n",
      "[I 2024-06-15 09:03:36,143] Trial 1 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.5251078090003678}. \n",
      "[I 2024-06-15 09:05:10,691] Trial 2 finished with values: [0.07, 0.12987012987012989] and parameters: {'weight_decay': 0.3119613264967052}. \n",
      "[I 2024-06-15 09:06:56,802] Trial 3 finished with values: [0.1154, 0.2164697445779392] and parameters: {'weight_decay': 0.0006480366471825574}. \n",
      "[I 2024-06-15 09:08:43,326] Trial 4 finished with values: [0.08339999999999999, 0.15054519615904052] and parameters: {'weight_decay': 0.06098757560407173}. \n",
      "[I 2024-06-15 09:08:43,328] A new study created in memory with name: Study - lr(10) hds(100) bs(3350) - 20240614T171400\n",
      "[I 2024-06-15 09:09:52,121] Trial 0 finished with values: [0.09514626865671644, 0.17301788007844593] and parameters: {'weight_decay': 0.7035880242818825}. \n",
      "[I 2024-06-15 09:11:00,808] Trial 1 finished with values: [0.09632238805970152, 0.1757770589741936] and parameters: {'weight_decay': 0.6760399758031632}. \n",
      "[I 2024-06-15 09:12:13,023] Trial 2 finished with values: [0.09503283582089554, 0.17307238607982525] and parameters: {'weight_decay': 0.4610140427998896}. \n",
      "[I 2024-06-15 09:13:25,959] Trial 3 finished with values: [0.09632835820895524, 0.17495988346343835] and parameters: {'weight_decay': 0.3777750231402919}. \n",
      "[I 2024-06-15 09:14:35,827] Trial 4 finished with values: [0.09536716417910449, 0.17339598181975885] and parameters: {'weight_decay': 0.4853528621657173}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_accuracy': 0.09514626865671644, 'best_f1': 0.17301788007844593}\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 1\n",
      "Best Accuracy: 0.184, Best F1 Score: 0.184\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 10\n",
      "Best Accuracy: 0.09319999999999999, Best F1 Score: 0.16461659451659452\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 50\n",
      "Best Accuracy: 0.1, Best F1 Score: 0.18067340504187468\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 25, Batch Size: 3350\n",
      "Best Accuracy: 0.12644776119402984, Best F1 Score: 0.20268156137405935\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 1\n",
      "Best Accuracy: 0.176, Best F1 Score: 0.176\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 10\n",
      "Best Accuracy: 0.09519999999999999, Best F1 Score: 0.16834254634254633\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 50\n",
      "Best Accuracy: 0.0922, Best F1 Score: 0.16189633687505506\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 50, Batch Size: 3350\n",
      "Best Accuracy: 0.12711044776119404, Best F1 Score: 0.21055531854360235\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 1\n",
      "Best Accuracy: 0.176, Best F1 Score: 0.176\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 10\n",
      "Best Accuracy: 0.09799999999999999, Best F1 Score: 0.16887715617715618\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 50\n",
      "Best Accuracy: 0.0882, Best F1 Score: 0.15039467412119048\n",
      "Learning Rate: 0.5, Hidden Dimension Size: 100, Batch Size: 3350\n",
      "Best Accuracy: 0.11764776119402984, Best F1 Score: 0.19075030429565287\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 1\n",
      "Best Accuracy: 0.196, Best F1 Score: 0.196\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 10\n",
      "Best Accuracy: 0.098, Best F1 Score: 0.17355656565656566\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 50\n",
      "Best Accuracy: 0.0692, Best F1 Score: 0.12239022461990831\n",
      "Learning Rate: 1, Hidden Dimension Size: 25, Batch Size: 3350\n",
      "Best Accuracy: 0.11386865671641791, Best F1 Score: 0.19592595636178156\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 1\n",
      "Best Accuracy: 0.18, Best F1 Score: 0.18\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 10\n",
      "Best Accuracy: 0.09759999999999999, Best F1 Score: 0.17195870795870796\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 50\n",
      "Best Accuracy: 0.07180000000000002, Best F1 Score: 0.12847061890822023\n",
      "Learning Rate: 1, Hidden Dimension Size: 50, Batch Size: 3350\n",
      "Best Accuracy: 0.11530149253731344, Best F1 Score: 0.1955192444341067\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 1\n",
      "Best Accuracy: 0.188, Best F1 Score: 0.188\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 10\n",
      "Best Accuracy: 0.09839999999999997, Best F1 Score: 0.17169175084175084\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 50\n",
      "Best Accuracy: 0.0698, Best F1 Score: 0.12343093042223478\n",
      "Learning Rate: 1, Hidden Dimension Size: 100, Batch Size: 3350\n",
      "Best Accuracy: 0.1092179104477612, Best F1 Score: 0.18565819725180752\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 1\n",
      "Best Accuracy: 0.0, Best F1 Score: 0.0\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 10\n",
      "Best Accuracy: 0.04, Best F1 Score: 0.07272727272727274\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 50\n",
      "Best Accuracy: 0.07, Best F1 Score: 0.12663278750235274\n",
      "Learning Rate: 10, Hidden Dimension Size: 25, Batch Size: 3350\n",
      "Best Accuracy: 0.09521791044776119, Best F1 Score: 0.16838521032625464\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 1\n",
      "Best Accuracy: 0.0, Best F1 Score: 0.0\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 10\n",
      "Best Accuracy: 0.04, Best F1 Score: 0.07272727272727274\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 50\n",
      "Best Accuracy: 0.07, Best F1 Score: 0.12987012987012989\n",
      "Learning Rate: 10, Hidden Dimension Size: 50, Batch Size: 3350\n",
      "Best Accuracy: 0.0941492537313433, Best F1 Score: 0.16941141544823762\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 1\n",
      "Best Accuracy: 0.0, Best F1 Score: 0.0\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 10\n",
      "Best Accuracy: 0.04, Best F1 Score: 0.07272727272727274\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 50\n",
      "Best Accuracy: 0.07, Best F1 Score: 0.12987012987012989\n",
      "Learning Rate: 10, Hidden Dimension Size: 100, Batch Size: 3350\n",
      "Best Accuracy: 0.09514626865671644, Best F1 Score: 0.17301788007844593\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Assuming the rest of your imports and setup code remains the same\n",
    "def train_and_evaluate_model(model, loss_func, optimizer, train_dataloader, val_dataloader, n_epochs, lr, hds, bs,weight_decay):   \n",
    "    with mlflow.start_run(run_name=f\"Testi \", nested = True):  # Name each run based on the learning rate\n",
    "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "        mlflow.log_param(\"batch_size\", bs)\n",
    "        mlflow.log_param(\"hidden_dim\", hds)\n",
    "        mlflow.log_param(\"lr\", lr)        \n",
    "\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Training loop\n",
    "            for inputs, targets in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_func(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            training_loss = loss\n",
    "            mlflow.log_metric(\"loss\", training_loss, step = epoch)\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            with torch.no_grad():\n",
    "                total_targets = 0\n",
    "                total_outputs = 0\n",
    "                for inputs, targets in val_dataloader:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_func(outputs, targets)\n",
    "                    val_losses.append(loss.item())\n",
    "\n",
    "                    _, preds = torch.max(outputs, dim=1)\n",
    "                    total_targets += targets.size(0)\n",
    "                    total_outputs += torch.sum(preds == targets.data)\n",
    "\n",
    "            total_labels = targets.numpy()\n",
    "            total_preds = preds.numpy()\n",
    "            acc = accuracy_score(total_labels, total_preds)\n",
    "            # precision = precision_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "            # recall = recall_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "            f1 = f1_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "\n",
    "            # acc = total_outputs / total_targets\n",
    "            # f1 = f1_score(targets.numpy(), preds.numpy())  # Assuming targets and preds are NumPy arrays\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            accuracies.append(acc)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            mlflow.log_metric(\"val_loss\", loss, step = epoch)\n",
    "            mlflow.log_metric(\"diff_loss_tr_ts\", training_loss-loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"accuracy\", acc, step = epoch)\n",
    "            # mlflow.log_metric(\"precision\", precision, step = epoch)\n",
    "            # mlflow.log_metric(\"recall\", recall, step = epoch)\n",
    "            mlflow.log_metric(\"f1\", f1, step = epoch)  \n",
    "\n",
    "        # return train_losses, val_losses, accuracies, f1_scores\n",
    "    return train_losses, val_losses, accuracies, f1_scores\n",
    "\n",
    "\n",
    "def objective(trial, lr, hds, bs, X_train, y_train):\n",
    "    text = \"Experiment - lr({lr}) hds({hds}) bs({bs})\".format(lr =lr,hds=hds,bs =bs)\n",
    "    with mlflow.start_run(run_name=text, experiment_id = mlflow_exp.experiment_id):\n",
    "        \n",
    "        # Suggest regularization parameter using the trial object\n",
    "        weight_decay = trial.suggest_float('weight_decay', 1e-5, 1)\n",
    "        \n",
    "        # Initialize the model with fixed hyperparameters and suggested regularization\n",
    "        model = NeuralNetwork(input_size=X_train.shape[1], hidden_dim=hds, output_size=10).to(device)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Perform k-fold cross-validation\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = {\"accuracy\": [], \"f1\": []}\n",
    "\n",
    "        for train_index, val_index in skf.split(X_train, y_train):\n",
    "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "            train_dataloader_fold = DataLoader(custom_mnist_dataset(X=X_train_fold, y=y_train_fold), batch_size=bs)\n",
    "            val_dataloader_fold = DataLoader(custom_mnist_dataset(X=X_val_fold, y=y_val_fold), batch_size=bs)\n",
    "\n",
    "            # Train and evaluate the model for this fold\n",
    "            train_loss, test_loss, accuracy, f1 = train_and_evaluate_model(\n",
    "                model, loss_func, optimizer, train_dataloader_fold, val_dataloader_fold, n_epochs=50, \n",
    "                lr=lr, hds=hds, bs=bs, weight_decay = weight_decay)\n",
    "\n",
    "            # Calculate average scores across all folds\n",
    "            cv_scores[\"accuracy\"].append(accuracy)\n",
    "            cv_scores[\"f1\"].append(f1)\n",
    "\n",
    "        # Return the average cross-validated scores\n",
    "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "        mlflow.log_param(\"batch_size\", bs)\n",
    "        mlflow.log_param(\"hidden_dim\", hds)\n",
    "        mlflow.log_param(\"lr\", lr)      \n",
    "        mlflow.log_metric(\"cv-accuracy\", np.mean(cv_scores[\"accuracy\"]))\n",
    "        mlflow.log_metric(\"cv-f1\",  np.mean(cv_scores[\"f1\"]))  \n",
    "                \n",
    "        return np.mean(cv_scores[\"accuracy\"]), np.mean(cv_scores[\"f1\"])\n",
    "\n",
    "# Fixed hyperparameters\n",
    "fixed_hyperparams = {\n",
    "    'learning_rates': [0.5, 1, 10],\n",
    "    'hidden_dim_sizes': [25, 50, 100],\n",
    "    'batch_sizes': [1, 10, 50, len(training_data)],\n",
    "}\n",
    "\n",
    "# watch out for n_trials, n_splits, n_epochs\n",
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.autolog()\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Convert to string in the format 'YYYY-MM-DD HH:MM:SS'\n",
    "formatted_now = now.strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "print(formatted_now)\n",
    "\n",
    "mlflow_exp = mlflow.set_experiment(experiment_name  = 'TP1ML - '+formatted_now)\n",
    "\n",
    "# Iterate over fixed hyperparameters\n",
    "best_results = {}\n",
    "for lr in fixed_hyperparams['learning_rates']:\n",
    "    for hds in fixed_hyperparams['hidden_dim_sizes']:\n",
    "        for bs in fixed_hyperparams['batch_sizes']:\n",
    "            # Create an Optuna study for each combination\n",
    "            # study = optuna.create_study(direction=('minimize', ('accuracy', 'f1')))\n",
    "            study_name =  \"Study - lr({lr}) hds({hds}) bs({bs}) - \".format(lr =lr,hds=hds,bs =bs)+formatted_now\n",
    "            study = optuna.create_study(directions=[\"minimize\", \"minimize\"],study_name =study_name )\n",
    "            study.optimize(lambda t: objective(t, lr, hds, bs, X_train, y_train), n_trials=5)  # Adjust n_trials as needed\n",
    "            \n",
    "            # Record the best trial\n",
    "            best_trial = study.best_trials[0]\n",
    "            best_accuracy = best_trial.values[0]\n",
    "            best_f1 = best_trial.values[1]\n",
    "            \n",
    "            # Record best results\n",
    "            best_results[(lr, hds, bs)] = {\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'best_f1': best_f1,\n",
    "            }\n",
    "        \n",
    "        print(best_results[(lr, hds, bs)])\n",
    "\n",
    "# Print the best results\n",
    "for (lr, hds, bs), result in best_results.items():\n",
    "    print(f\"Learning Rate: {lr}, Hidden Dimension Size: {hds}, Batch Size: {bs}\")\n",
    "    print(f\"Best Accuracy: {result['best_accuracy']}, Best F1 Score: {result['best_f1']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
