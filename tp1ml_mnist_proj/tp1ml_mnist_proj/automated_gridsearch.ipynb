{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7   0  84 185 159 151  60  36 222 254 241 198 170  52  67 114  72 163\n",
      " 227 225 250 229 140  17  66  14  59  21 236 106  83 253 209  18  22 233\n",
      " 255 129 238  44 249  62 133 187   5   9 205 248  58 126 182  75 251 240\n",
      "  57  19 221 166   3 203 219  35  38  77  31 224 115   1  61 242 121  40\n",
      " 207]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  7  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  2  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  784  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data_tp1.csv',header=None)\n",
    "data = data.rename(columns={0:'y'})\n",
    "print(data.iloc[0,:].unique())\n",
    "\n",
    "imsize = round(np.sqrt(784)+1)\n",
    "linha_y = 4\n",
    "img = np.reshape(data.iloc[linha_y,1:].values, (imsize-1,imsize-1))\n",
    "plt.imshow(img)\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def data and model shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 784)\n",
      "(3350,)\n",
      "(784,)\n",
      "7\n",
      "Shape, type: X: torch.Size([25, 784]) torch.float32\n",
      "Shape, type: y: torch.Size([25]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data.y.values\n",
    "X = data.drop(columns='y').values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "idx = 0\n",
    "print((X_train[idx,:]).shape)\n",
    "print(y_train[idx])\n",
    "(y_train[idx]).shape \n",
    "\n",
    "# Pytorch exige que seja utilizado um dataset por algum motivo aparentemente\n",
    "class custom_mnist_dataset():\n",
    "    def __init__(self, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # RestriÃ§Ãµes de uso do pytorch: (leia os docs...)\n",
    "        # inputs tem que ser float para multiplicar pelos pesos, \n",
    "        # outputs tem que ser longint para calcular crossentropy \n",
    "        return torch.tensor(self.X[idx,:], dtype=torch.float), self.y[idx]\n",
    "\n",
    "training_data = custom_mnist_dataset(X = X_train, y = y_train)\n",
    "test_data = custom_mnist_dataset(X = X_test, y = y_test)\n",
    "\n",
    "# batch_size de exemplo para teste\n",
    "batch_size = 25\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape, type: X: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape, type: y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (entrada): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (oculta): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (saida): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "NeuralNetwork with  ...\n",
    "\"\"\"\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.entrada = nn.Linear(input_size, hidden_dim)\n",
    "        self.oculta = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.saida = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x1 = self.entrada(input)\n",
    "        x2 = F.sigmoid(self.oculta(x1))\n",
    "        x3 = self.saida(x2)\n",
    "\n",
    "        return x3\n",
    "    \n",
    "# hidden dim = 25,50,100\n",
    "print(NeuralNetwork(input_size = X_train.shape[1], hidden_dim= 25, output_size=10).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def train, test and eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/shrutimechlearn/pytorch-custom-model-step-by-step\n",
    "\n",
    "def train_step(model, loss_func, optimizer, dataloader):\n",
    "    \n",
    "    # to capture loss\n",
    "    train_loss = 0 \n",
    "\n",
    "    # to get the model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        # sending data to the device where rest of the artifacts are\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # forward pass/model prediction with the given input\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # loss calculation by comparison between predicted and ground truth values\n",
    "        loss = loss_func(y_pred, y_batch)\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "        # setting previously collected gradient values in the optimizer to zero so it translates only current gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate the gradients for this iteration (independent gradients because previous values have been reset to 0)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights and biases based on the calculated gradients ~(wi = wi + delta_wi)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, loss_func, test_dataloader):\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for batch, (x_batch, y_batch) in enumerate(test_dataloader):\n",
    "            \n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            loss = loss_func(y_pred, y_batch)\n",
    "            test_loss+= loss.item()\n",
    "\n",
    "    test_loss = test_loss/len(test_dataloader)   \n",
    "\n",
    "    return test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch import optim\n",
    "\n",
    "def eval_step_with_mlflowlogging(model,test_dataloader):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_preds = []\n",
    "        total_labels = []\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(total_labels, total_preds)\n",
    "    precision = precision_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    recall = recall_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def train_with_mlflowlogging(model, loss_func, optimizer, train_dataloader, test_dataloader, n_epochs, i,lr,hds,bs):\n",
    "    with mlflow.start_run(run_name=f\"Test #{i} - lr({lr}) hds({hds}) bs({bs})\", nested = True):  # Name each run based on the learning rate\n",
    "        mlflow.log_param(\"batch_size\", bs)\n",
    "        mlflow.log_param(\"hidden_dim\", hds)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        \n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "    \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            tr_loss = train_step(model, loss_func, optimizer, train_dataloader)\n",
    "            train_loss.append(tr_loss)\n",
    "        \n",
    "            ts_loss = test_step(model, loss_func, test_dataloader)\n",
    "            test_loss.append(ts_loss)    \n",
    "\n",
    "            accuracy, precision, recall, f1 = eval_step_with_mlflowlogging(model, test_dataloader)\n",
    "            \n",
    "            mlflow.log_metric(\"loss\", tr_loss, step = epoch)\n",
    "            mlflow.log_metric(\"val_loss\", ts_loss, step = epoch)\n",
    "            mlflow.log_metric(\"diff_loss_tr_ts\", tr_loss-ts_loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"loss\", tr_loss, step = epoch)\n",
    "            mlflow.log_metric(\"val_loss\", ts_loss, step = epoch)\n",
    "\n",
    "            mlflow.log_metric(\"accuracy\", accuracy, step = epoch)\n",
    "            mlflow.log_metric(\"precision\", precision, step = epoch)\n",
    "            mlflow.log_metric(\"recall\", recall, step = epoch)\n",
    "            mlflow.log_metric(\"f1\", f1, step = epoch)   \n",
    "\n",
    "    return train_loss, test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def automated trials and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/05 18:54:07 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2024/06/05 18:54:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of starting an MLflow run and integrating Optuna for hyperparameter tuning\n",
    "# with mlflow.start_run():\n",
    "#     def objective(trial):\n",
    "#         # Use trial.suggest_* methods to suggest hyperparameters\n",
    "#         # batch_size = 10,50,len(training_data)\n",
    "#         batch_size = len(training_data)\n",
    "        \n",
    "#         # hidden dim = 25,50,100\n",
    "#         hidden_dim =100\n",
    "\n",
    "#         # GB, SGD batch 1, SGD minibatch 10 e 50\n",
    "#         # lr = 0.5, 1, 10\n",
    "#         lr = 0.5\n",
    "\n",
    "#         # Log params\n",
    "#         mlflow.log_param(\"batch_size\", batch_size)\n",
    "#         mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "#         mlflow.log_param(\"lr\", lr)\n",
    "\n",
    "#         # Define your model here\n",
    "#         train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "#         test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#         model = NeuralNetwork(input_size = X_train.shape[1], hidden_dim= hidden_dim, output_size=10).to(device)\n",
    "\n",
    "#         loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "#         optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "#         train_loss, test_loss = train_with_mlflowlogging(\n",
    "#             model, \n",
    "#             loss_func, \n",
    "#             optimizer, \n",
    "#             train_dataloader, \n",
    "#             test_dataloader, \n",
    "#             n_epochs= 20)\n",
    "\n",
    "#         # mlflow.log_metric(\"loss\", train_loss[-1])\n",
    "#         # mlflow.log_metric(\"val_loss\", test_loss[-1])\n",
    "\n",
    "#         return  test_loss[-1]  # Return a value to minimize (e.g., negative accuracy)\n",
    "\n",
    "#     study = optuna.create_study(direction=\"minimize\", study_name = \"testing_mlflow_optuna_2\", load_if_exists = True)\n",
    "#     study.optimize(objective, n_trials=10)\n",
    "    \n",
    "#     # Log the best parameters and other relevant information\n",
    "#     mlflow.log_params(study.best_params)\n",
    "#     mlflow.log_metric(\"best_loss\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.5, 1, 10]\n",
    "# hidden_dim_sizes = [25, 50, 100]\n",
    "# batch_sizes = [10, 50, len(training_data)]\n",
    "\n",
    "# mlflow_exp = mlflow.set_experiment(experiment_name  = 'TP1ML_automation_test')\n",
    "\n",
    "# with mlflow.start_run(run_name=\"Test Experiment 1\", experiment_id = mlflow_exp.experiment_id):\n",
    "\n",
    "#     for i_lr, lr in enumerate(learning_rates, start=1):\n",
    "#         for i_hds, hds in enumerate(hidden_dim_sizes, start = 1):\n",
    "#             for i_bs, bs in enumerate(batch_sizes, start = 1):\n",
    "                \n",
    "#                 # Define your model here\n",
    "#                 train_dataloader = DataLoader(training_data, batch_size=bs)\n",
    "#                 test_dataloader = DataLoader(test_data, batch_size=bs)\n",
    "\n",
    "#                 model = NeuralNetwork(input_size = X_train.shape[1], hidden_dim= hds, output_size=10).to(device)\n",
    "\n",
    "#                 loss_func = nn.CrossEntropyLoss()\n",
    "                \n",
    "#                 optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "#                 train_loss, test_loss = train_with_mlflowlogging(\n",
    "#                     model, \n",
    "#                     loss_func, \n",
    "#                     optimizer, \n",
    "#                     train_dataloader, \n",
    "#                     test_dataloader, \n",
    "#                     n_epochs= 200,\n",
    "#                     i=i_lr+i_hds+i_bs,\n",
    "#                     lr=lr,hds=hds,bs=bs\n",
    "#                 )\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.5, 1, 10]\n",
    "# hidden_dim_sizes = [25, 50, 100]\n",
    "# batch_sizes = [1, 10, 50, len(training_data)]\n",
    "\n",
    "# mlflow_exp = mlflow.set_experiment(experiment_name  = 'TP1ML_automation_test')\n",
    "\n",
    "# with mlflow.start_run(run_name=\"Test Experiment 2\", experiment_id = mlflow_exp.experiment_id):\n",
    "    \n",
    "#     for i_hds, hds in enumerate(hidden_dim_sizes, start = 1):\n",
    "#         for i_bs, bs in enumerate(batch_sizes, start = 1):\n",
    "#             for i_lr, lr in enumerate(learning_rates, start=1):\n",
    "                \n",
    "#                 # Define your model here\n",
    "#                 train_dataloader = DataLoader(training_data, batch_size=bs)\n",
    "#                 test_dataloader = DataLoader(test_data, batch_size=bs)\n",
    "\n",
    "#                 model = NeuralNetwork(input_size = X_train.shape[1], hidden_dim= hds, output_size=10).to(device)\n",
    "\n",
    "#                 loss_func = nn.CrossEntropyLoss()\n",
    "                \n",
    "#                 optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "#                 train_loss, test_loss = train_with_mlflowlogging(\n",
    "#                     model, \n",
    "#                     loss_func, \n",
    "#                     optimizer, \n",
    "#                     train_dataloader, \n",
    "#                     test_dataloader, \n",
    "#                     n_epochs= 20,\n",
    "#                     i=i_lr+i_hds+i_bs,\n",
    "#                     lr=lr,hds=hds,bs=bs\n",
    "#                 )\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m---> 23\u001b[0m train_loss, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_mlflowlogging\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi_lr\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi_hds\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi_bs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m, in \u001b[0;36mtrain_with_mlflowlogging\u001b[1;34m(model, loss_func, optimizer, train_dataloader, test_dataloader, n_epochs, i, lr, hds, bs)\u001b[0m\n\u001b[0;32m     31\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m---> 35\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(tr_loss)\n\u001b[0;32m     38\u001b[0m     ts_loss \u001b[38;5;241m=\u001b[39m test_step(model, loss_func, test_dataloader)\n",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, loss_func, optimizer, dataloader)\u001b[0m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# loss calculation by comparison between predicted and ground truth values\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# setting previously collected gradient values in the optimizer to zero so it translates only current gradients\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\miniconda3\\envs\\tp1ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\miniconda3\\envs\\tp1ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\miniconda3\\envs\\tp1ml\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\miniconda3\\envs\\tp1ml\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found run IDs: ['b5198fcd7e244c4fa1df5d4273af6a07']\n",
      "Child run IDs: ['a51f555a9bdc4a18a9512e739d81a416', '830acb052ffa4cde92362a298e28a4af', 'ae2474881cc54f2fad467b5d57c1ba47', '853af11fa4ba4452af718367ad079e74', '4b8f4525745b4ff8ad24412629e88eab', '55d8984d6df14d8bb086018106f5a5c4', '0649eb33e2db4358b9f4c94bcb59235f', 'bb9fdb2f94544b24969699dfca0c7df1', 'c2ed5249e1794c7abfff01eafa08135c', 'f34b8fe2fe0a4828ac1176c9561f3bdc', 'f92f2926aa8c4251af0b9652a3cbf73f', '520c9fa38f7f4a0e87a4da1b6953f09a', '48bdab3b235e4ef6b817f2eeae3c3efd', '25e322dc21234087971bea1dd4524865', '537110f48a55430ba51762d65f0250a2', '6c1a38241e6a4998a5ec698580921345', '8caa6498d64a4bda9930c30730057af4', '312d55baa42f483db1ca689c60dcfc3f', '85a6b77a06304faab132cc12e5e696e9', '1cad077f0b144f568fc64d1713eeb776', 'ddd93bce6f0f49a4854a12a44a1e95da', '09137e15cbfa4ec3bec0dce6bef0f304', '9435acaa92294ec6a64b53082adaf0c4', '33cf952990f14328a72bd1e285f87647', '261e1d6742054642b42a796ebb884199', '1b5a9858476541dfa1700c41236f63d3', 'dff2efe5078b44c086c2ef1a39d71c4b', 'bce32dffd715476b9f0bb0cda16a87eb', '37562af05af24dc4aeced35db9459820', '12d25eeffdd647e297740a3898924b74', 'fed64fce9aae4982913840953d9f7079', '38bee0b79e814fc3950cf776e9278e8e', 'cdfabdeba1ac4c70a8ba7a4b1b964e82', 'c05eace797ac4027aae1a26a1a355fa5', 'adc314edea3548e9a31135ca6ecc00b3', '12932ddb090345af97a1ea7c9b5c6db4']\n"
     ]
    }
   ],
   "source": [
    "# Specify the run name you're searching for\n",
    "run_name = \"Test Experiment 3\"\n",
    "\n",
    "# Search for the run by name\n",
    "runs_df = mlflow.search_runs(filter_string=f\"run_name='{run_name}'\")\n",
    "\n",
    "# Get the run ID(s) of the matching run(s)\n",
    "run_ids = runs_df['run_id'].tolist()\n",
    "\n",
    "print(f\"Found run IDs: {run_ids}\")\n",
    "\n",
    "# Replace 'your_parent_run_id' with the actual parent run ID\n",
    "parent_run_id = run_ids[0]\n",
    "\n",
    "# Construct the filter string to search for child runs of the parent run\n",
    "filter_string = f\"tags.mlflow.parentRunId='{parent_run_id}'\"\n",
    "\n",
    "# Search for the child runs\n",
    "child_runs_df = mlflow.search_runs(filter_string=filter_string)\n",
    "\n",
    "# Extract the run IDs of the child runs\n",
    "child_run_ids = child_runs_df['run_id'].tolist()\n",
    "\n",
    "print(f\"Child run IDs: {child_run_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('3350', '100', '10'): {'accuracy': 0.08727272727272728,\n",
       "  'f1': 0.1605351170568562,\n",
       "  'loss': 169.8508758544922,\n",
       "  'precision': 0.08727272727272728,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 188.4224853515625},\n",
       " ('3350', '100', '1'): {'accuracy': 0.6084848484848485,\n",
       "  'f1': 0.5470619835270794,\n",
       "  'loss': 1.3099318742752075,\n",
       "  'precision': 0.6800198268283064,\n",
       "  'recall': 0.6084848484848485,\n",
       "  'val_loss': 1.0960403680801392},\n",
       " ('3350', '100', '0.5'): {'accuracy': 0.6581818181818182,\n",
       "  'f1': 0.6374450780573804,\n",
       "  'loss': 1.016547679901123,\n",
       "  'precision': 0.7617506449835256,\n",
       "  'recall': 0.6581818181818182,\n",
       "  'val_loss': 0.9476253390312195},\n",
       " ('50', '100', '10'): {'accuracy': 0.24666666666666667,\n",
       "  'f1': 0.32623313909392926,\n",
       "  'loss': 83.1508100139561,\n",
       "  'precision': 0.503385048172734,\n",
       "  'recall': 0.41786447638603696,\n",
       "  'val_loss': 84.06985531431256},\n",
       " ('50', '100', '1'): {'accuracy': 0.09151515151515152,\n",
       "  'f1': 0.1676846196557468,\n",
       "  'loss': 10.573723771678868,\n",
       "  'precision': 0.09151515151515152,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 13.25415293375651},\n",
       " ('50', '100', '0.5'): {'accuracy': 0.2290909090909091,\n",
       "  'f1': 0.3851196481013515,\n",
       "  'loss': 2.4252346843036254,\n",
       "  'precision': 0.3509388294141794,\n",
       "  'recall': 0.5806451612903226,\n",
       "  'val_loss': 2.874348933046514},\n",
       " ('10', '100', '10'): {'accuracy': 0.09151515151515152,\n",
       "  'f1': 0.1676846196557468,\n",
       "  'loss': 226.20833792615292,\n",
       "  'precision': 0.09151515151515152,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 263.0736347545277},\n",
       " ('10', '100', '1'): {'accuracy': 0.13333333333333333,\n",
       "  'f1': 0.19865913612335098,\n",
       "  'loss': 22.53579708213237,\n",
       "  'precision': 0.1931662083973141,\n",
       "  'recall': 0.4339250493096647,\n",
       "  'val_loss': 21.7618182962591},\n",
       " ('10', '100', '0.5'): {'accuracy': 0.13393939393939394,\n",
       "  'f1': 0.1408605418269333,\n",
       "  'loss': 5.639075818702356,\n",
       "  'precision': 0.3801837748972053,\n",
       "  'recall': 0.265625,\n",
       "  'val_loss': 7.868669017155965},\n",
       " ('1', '100', '10'): {'accuracy': 0.10242424242424242,\n",
       "  'f1': 0.1858163826278175,\n",
       "  'loss': 441.2925374045301,\n",
       "  'precision': 0.10242424242424242,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 469.29285877574574},\n",
       " ('1', '100', '1'): {'accuracy': 0.24484848484848484,\n",
       "  'f1': 0.2591185086443162,\n",
       "  'loss': 38.64489805093806,\n",
       "  'precision': 0.5144932818614114,\n",
       "  'recall': 0.3488773747841105,\n",
       "  'val_loss': 48.8722723804482},\n",
       " ('1', '100', '0.5'): {'accuracy': 0.22363636363636363,\n",
       "  'f1': 0.20263823086277108,\n",
       "  'loss': 14.643330542988554,\n",
       "  'precision': 0.5168100056365857,\n",
       "  'recall': 0.24616410940627084,\n",
       "  'val_loss': 17.178205482703586},\n",
       " ('3350', '50', '10'): {'accuracy': 0.11333333333333333,\n",
       "  'f1': 0.20359281437125748,\n",
       "  'loss': 28.43450164794922,\n",
       "  'precision': 0.11333333333333333,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 27.759889602661133},\n",
       " ('3350', '50', '1'): {'accuracy': 0.6012121212121212,\n",
       "  'f1': 0.561342416749777,\n",
       "  'loss': 1.3389360904693604,\n",
       "  'precision': 0.6473719971741482,\n",
       "  'recall': 0.6012121212121212,\n",
       "  'val_loss': 1.1068031787872314},\n",
       " ('3350', '50', '0.5'): {'accuracy': 0.7533333333333333,\n",
       "  'f1': 0.7416091341056316,\n",
       "  'loss': 0.9482134580612183,\n",
       "  'precision': 0.7888092373045779,\n",
       "  'recall': 0.7533333333333333,\n",
       "  'val_loss': 0.9246416091918945},\n",
       " ('50', '50', '10'): {'accuracy': 0.09151515151515152,\n",
       "  'f1': 0.1676846196557468,\n",
       "  'loss': 103.50234017443302,\n",
       "  'precision': 0.09151515151515152,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 140.1235700665098},\n",
       " ('50', '50', '1'): {'accuracy': 0.09151515151515152,\n",
       "  'f1': 0.1676846196557468,\n",
       "  'loss': 2.871257255326456,\n",
       "  'precision': 0.09151515151515152,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 3.0801331491181343},\n",
       " ('50', '50', '0.5'): {'accuracy': 0.09151515151515152,\n",
       "  'f1': 0.1676846196557468,\n",
       "  'loss': 2.527374602075833,\n",
       "  'precision': 0.09151515151515152,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 2.6845212921951758},\n",
       " ('10', '50', '10'): {'accuracy': 0.11818181818181818,\n",
       "  'f1': 0.17167174280100464,\n",
       "  'loss': 129.44078946469435,\n",
       "  'precision': 0.11487469928922031,\n",
       "  'recall': 0.5752212389380531,\n",
       "  'val_loss': 168.19730122884116},\n",
       " ('10', '50', '1'): {'accuracy': 0.09212121212121212,\n",
       "  'f1': 0.16870144284128746,\n",
       "  'loss': 6.436784251768198,\n",
       "  'precision': 0.09212121212121212,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 5.046131577636256},\n",
       " ('10', '50', '0.5'): {'accuracy': 0.10242424242424242,\n",
       "  'f1': 0.1858163826278175,\n",
       "  'loss': 3.244754186317102,\n",
       "  'precision': 0.10242424242424242,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 3.6648311759486343},\n",
       " ('1', '50', '10'): {'accuracy': 0.10242424242424242,\n",
       "  'f1': 0.1858163826278175,\n",
       "  'loss': 243.16119239921,\n",
       "  'precision': 0.10242424242424242,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 305.10157840613164},\n",
       " ('1', '50', '1'): {'accuracy': 0.15454545454545454,\n",
       "  'f1': 0.3982216597405259,\n",
       "  'loss': 20.546979706644642,\n",
       "  'precision': 0.4414640481636923,\n",
       "  'recall': 0.7327586206896551,\n",
       "  'val_loss': 23.181649179892776},\n",
       " ('1', '50', '0.5'): {'accuracy': 0.18424242424242424,\n",
       "  'f1': 0.4923743153810058,\n",
       "  'loss': 11.895145934889303,\n",
       "  'precision': 0.4506082535843243,\n",
       "  'recall': 0.8735632183908046,\n",
       "  'val_loss': 14.896102801338412},\n",
       " ('3350', '25', '10'): {'accuracy': 0.09454545454545454,\n",
       "  'f1': 0.08866820471472933,\n",
       "  'loss': 6.234524250030518,\n",
       "  'precision': 0.049184422098981696,\n",
       "  'recall': 0.4495677233429395,\n",
       "  'val_loss': 5.346619129180908},\n",
       " ('3350', '25', '1'): {'accuracy': 0.4175757575757576,\n",
       "  'f1': 0.3531750466238602,\n",
       "  'loss': 1.4811397790908813,\n",
       "  'precision': 0.5779692534327477,\n",
       "  'recall': 0.4175757575757576,\n",
       "  'val_loss': 1.6021677255630493},\n",
       " ('3350', '25', '0.5'): {'accuracy': 0.7096969696969697,\n",
       "  'f1': 0.7020703932309623,\n",
       "  'loss': 1.223462700843811,\n",
       "  'precision': 0.7212886717632045,\n",
       "  'recall': 0.7096969696969697,\n",
       "  'val_loss': 1.2007317543029785},\n",
       " ('50', '25', '10'): {'accuracy': 0.10303030303030303,\n",
       "  'f1': 0.18681318681318682,\n",
       "  'loss': 40.86275243047458,\n",
       "  'precision': 0.10303030303030303,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 47.20806191184304},\n",
       " ('50', '25', '1'): {'accuracy': 0.27515151515151515,\n",
       "  'f1': 0.46933851345313166,\n",
       "  'loss': 1.99643453199472,\n",
       "  'precision': 0.414461797940863,\n",
       "  'recall': 0.7252396166134185,\n",
       "  'val_loss': 2.1786488077857276},\n",
       " ('50', '25', '0.5'): {'accuracy': 0.2672727272727273,\n",
       "  'f1': 0.22801028198192627,\n",
       "  'loss': 1.9688084588122012,\n",
       "  'precision': 0.3467927204518976,\n",
       "  'recall': 0.37436332767402375,\n",
       "  'val_loss': 1.973024025107875},\n",
       " ('10', '25', '10'): {'accuracy': 0.13696969696969696,\n",
       "  'f1': 0.2422749955169518,\n",
       "  'loss': 51.99457459236259,\n",
       "  'precision': 0.15383189375677736,\n",
       "  'recall': 0.70625,\n",
       "  'val_loss': 50.754403883038144},\n",
       " ('10', '25', '1'): {'accuracy': 0.11212121212121212,\n",
       "  'f1': 0.15973388652013915,\n",
       "  'loss': 4.445707782346811,\n",
       "  'precision': 0.09756563036834354,\n",
       "  'recall': 0.5763239875389408,\n",
       "  'val_loss': 5.6303650957165345},\n",
       " ('10', '25', '0.5'): {'accuracy': 0.10242424242424242,\n",
       "  'f1': 0.1858163826278175,\n",
       "  'loss': 2.6094795910280144,\n",
       "  'precision': 0.10242424242424242,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 2.8360102617379392},\n",
       " ('1', '25', '10'): {'accuracy': 0.10242424242424242,\n",
       "  'f1': 0.1858163826278175,\n",
       "  'loss': 99.06567240814664,\n",
       "  'precision': 0.10242424242424242,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 106.22204247676964},\n",
       " ('1', '25', '1'): {'accuracy': 0.13515151515151516,\n",
       "  'f1': 0.11720009124349279,\n",
       "  'loss': 7.955462135128542,\n",
       "  'precision': 0.5315493717815182,\n",
       "  'recall': 0.22277722277722278,\n",
       "  'val_loss': 7.623942322768842},\n",
       " ('1', '25', '0.5'): {'accuracy': 0.10242424242424242,\n",
       "  'f1': 0.1858163826278175,\n",
       "  'loss': 5.8674340322922305,\n",
       "  'precision': 0.10242424242424242,\n",
       "  'recall': 1.0,\n",
       "  'val_loss': 6.002018170903691}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "params_and_metrics = dict()\n",
    "for run_id in child_run_ids:\n",
    "    run = client.get_run(run_id)\n",
    "    params =[val for k, val in run.data.params.items()]\n",
    "    metrics = run.data.metrics\n",
    "\n",
    "    params_and_metrics[*params] = metrics\n",
    "    # client.get_metric_history(run_id, 'val_loss')\n",
    "\n",
    "params_and_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
