{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  7  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  2  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  784  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data_tp1.csv',header=None)\n",
    "data = data.rename(columns={0:'y'})\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data.y.values\n",
    "X = data.drop(columns='y').values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 784)\n",
      "(3350,)\n",
      "(784,)\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "idx = 0\n",
    "print((X_train[idx,:]).shape)\n",
    "print(y_train[idx])\n",
    "(y_train[idx]).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([25, 784]) torch.float32\n",
      "Shape of y: torch.Size([25]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Pytorch exige que seja utilizado um dataset por algum motivo aparentemente\n",
    "class custom_mnist_dataset():\n",
    "    def __init__(self, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Restrições de uso do pytorch: (leia os docs...)\n",
    "        # inputs tem que ser float para multiplicar pelos pesos, \n",
    "        # outputs tem que ser longint para calcular crossentropy \n",
    "        return torch.tensor(self.X[idx,:], dtype=torch.float), self.y[idx]\n",
    "\n",
    "training_data = custom_mnist_dataset(X = X_train, y = y_train)\n",
    "test_data = custom_mnist_dataset(X = X_test, y = y_test)\n",
    "\n",
    "# batch_size = 10,50\n",
    "batch_size = 25\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape, type: X: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape, type: y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (entrada): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (oculta): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (saida): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "NeuralNetwork with  ...\n",
    "\"\"\"\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.entrada = nn.Linear(input_size, hidden_dim)\n",
    "        self.oculta = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.saida = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x1 = self.entrada(input)\n",
    "        x2 = F.sigmoid(self.oculta(x1))\n",
    "        x3 = self.saida(x2)\n",
    "\n",
    "        return x3\n",
    "    \n",
    "# hidden dim = 25,50,100\n",
    "print(NeuralNetwork(input_size = X_train.shape[1], hidden_dim= 25, output_size=10).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/shrutimechlearn/pytorch-custom-model-step-by-step\n",
    "\n",
    "def train_step(model, loss_func, optimizer, dataloader):\n",
    "    \n",
    "    # to capture loss\n",
    "    train_loss = 0 \n",
    "\n",
    "    # to get the model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        # sending data to the device where rest of the artifacts are\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # forward pass/model prediction with the given input\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # loss calculation by comparison between predicted and ground truth values\n",
    "        loss = loss_func(y_pred, y_batch)\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "        # setting previously collected gradient values in the optimizer to zero so it translates only current gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate the gradients for this iteration (independent gradients because previous values have been reset to 0)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights and biases based on the calculated gradients ~(wi = wi + delta_wi)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, loss_func, test_dataloader):\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for batch, (x_batch, y_batch) in enumerate(test_dataloader):\n",
    "            \n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            loss = loss_func(y_pred, y_batch)\n",
    "            test_loss+= loss.item()\n",
    "\n",
    "    test_loss = test_loss/len(test_dataloader)   \n",
    "\n",
    "    return test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/04 11:50:59 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2024/06/04 11:50:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "[I 2024-06-04 11:51:01,786] A new study created in memory with name: testing_mlflow_optuna_2\n",
      "[I 2024-06-04 11:51:08,089] Trial 0 finished with value: 1.6329529285430908 and parameters: {}. Best is trial 0 with value: 1.6329529285430908.\n",
      "[I 2024-06-04 11:51:14,478] Trial 1 finished with value: 1.3337547779083252 and parameters: {}. Best is trial 1 with value: 1.3337547779083252.\n",
      "[I 2024-06-04 11:51:21,765] Trial 2 finished with value: 1.3339941501617432 and parameters: {}. Best is trial 1 with value: 1.3337547779083252.\n",
      "[I 2024-06-04 11:51:29,473] Trial 3 finished with value: 1.3230894804000854 and parameters: {}. Best is trial 3 with value: 1.3230894804000854.\n",
      "[I 2024-06-04 11:51:36,761] Trial 4 finished with value: 1.3764618635177612 and parameters: {}. Best is trial 3 with value: 1.3230894804000854.\n",
      "[I 2024-06-04 11:51:44,148] Trial 5 finished with value: 1.2828726768493652 and parameters: {}. Best is trial 5 with value: 1.2828726768493652.\n",
      "[I 2024-06-04 11:51:50,888] Trial 6 finished with value: 1.4059487581253052 and parameters: {}. Best is trial 5 with value: 1.2828726768493652.\n",
      "[I 2024-06-04 11:51:57,658] Trial 7 finished with value: 1.3312320709228516 and parameters: {}. Best is trial 5 with value: 1.2828726768493652.\n",
      "[I 2024-06-04 11:52:04,986] Trial 8 finished with value: 1.3587099313735962 and parameters: {}. Best is trial 5 with value: 1.2828726768493652.\n",
      "[I 2024-06-04 11:52:12,036] Trial 9 finished with value: 1.456808090209961 and parameters: {}. Best is trial 5 with value: 1.2828726768493652.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "\n",
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri('http://localhost:8080')\n",
    "mlflow.autolog()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def eval_step_with_mlflowlogging(model,test_dataloader):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_preds = []\n",
    "        total_labels = []\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(total_labels, total_preds)\n",
    "    precision = precision_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    recall = recall_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def train_with_mlflowlogging(model, loss_func, optimizer, train_dataloader, test_dataloader, n_epochs):\n",
    "    \n",
    "    train_loss = []\n",
    "    \n",
    "    test_loss = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        tr_loss = train_step(model, loss_func, optimizer, train_dataloader)\n",
    "        train_loss.append(tr_loss)\n",
    "    \n",
    "        ts_loss = test_step(model, loss_func, test_dataloader)\n",
    "        test_loss.append(ts_loss)    \n",
    "\n",
    "        accuracy, precision, recall, f1 = eval_step_with_mlflowlogging(model, test_dataloader)\n",
    "        \n",
    "        mlflow.log_metric(\"loss\", tr_loss)#, step = epoch)\n",
    "        mlflow.log_metric(\"val_loss\", ts_loss)#, step = epoch)\n",
    "\n",
    "        mlflow.log_metric(\"loss\", tr_loss)#, step = epoch)\n",
    "        mlflow.log_metric(\"val_loss\", ts_loss)#, step = epoch)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)#, step = epoch)\n",
    "        mlflow.log_metric(\"precision\", precision)#, step = epoch)\n",
    "        mlflow.log_metric(\"recall\", recall)#, step = epoch)\n",
    "        mlflow.log_metric(\"f1\", f1, step = epoch)#)   \n",
    "\n",
    "    return train_loss, test_loss\n",
    "\n",
    "# Example of starting an MLflow run and integrating Optuna for hyperparameter tuning\n",
    "with mlflow.start_run():\n",
    "    def objective(trial):\n",
    "        # Use trial.suggest_* methods to suggest hyperparameters\n",
    "        # batch_size = 10,50,len(training_data)\n",
    "        batch_size = len(training_data)\n",
    "        \n",
    "        # hidden dim = 25,50,100\n",
    "        hidden_dim =25\n",
    "\n",
    "        # GB, SGD batch 1, SGD minibatch 10 e 50\n",
    "        # lr = 0.5, 1, 10\n",
    "        lr = 0.5\n",
    "\n",
    "        # Log params\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "\n",
    "        # Define your model here\n",
    "        train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "        model = NeuralNetwork(input_size = X_train.shape[1], hidden_dim= hidden_dim, output_size=10).to(device)\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        train_loss, test_loss = train_with_mlflowlogging(\n",
    "            model, \n",
    "            loss_func, \n",
    "            optimizer, \n",
    "            train_dataloader, \n",
    "            test_dataloader, \n",
    "            n_epochs= 20)\n",
    "\n",
    "        # mlflow.log_metric(\"loss\", train_loss[-1])\n",
    "        # mlflow.log_metric(\"val_loss\", test_loss[-1])\n",
    "\n",
    "        return  test_loss[-1]  # Return a value to minimize (e.g., negative accuracy)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name = \"testing_mlflow_optuna_2\", load_if_exists = True)\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # Log the best parameters and other relevant information\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_loss\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/04 11:54:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2024/06/04 11:54:00 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "[I 2024-06-04 11:54:00,290] A new study created in memory with name: testing_mlflow_optuna_2\n",
      "[I 2024-06-04 11:54:06,695] Trial 0 finished with value: 0.8673474788665771 and parameters: {}. Best is trial 0 with value: 0.8673474788665771.\n",
      "[I 2024-06-04 11:54:14,062] Trial 1 finished with value: 0.9595535397529602 and parameters: {}. Best is trial 0 with value: 0.8673474788665771.\n",
      "[I 2024-06-04 11:54:21,963] Trial 2 finished with value: 0.875180721282959 and parameters: {}. Best is trial 0 with value: 0.8673474788665771.\n",
      "[I 2024-06-04 11:54:29,926] Trial 3 finished with value: 0.7136643528938293 and parameters: {}. Best is trial 3 with value: 0.7136643528938293.\n",
      "[I 2024-06-04 11:54:37,655] Trial 4 finished with value: 0.8426854610443115 and parameters: {}. Best is trial 3 with value: 0.7136643528938293.\n",
      "[I 2024-06-04 11:54:45,584] Trial 5 finished with value: 0.7893187999725342 and parameters: {}. Best is trial 3 with value: 0.7136643528938293.\n",
      "[I 2024-06-04 11:54:53,745] Trial 6 finished with value: 1.160524845123291 and parameters: {}. Best is trial 3 with value: 0.7136643528938293.\n",
      "[I 2024-06-04 11:55:01,948] Trial 7 finished with value: 1.1418824195861816 and parameters: {}. Best is trial 3 with value: 0.7136643528938293.\n",
      "[I 2024-06-04 11:55:09,835] Trial 8 finished with value: 0.8571752309799194 and parameters: {}. Best is trial 3 with value: 0.7136643528938293.\n",
      "[I 2024-06-04 11:55:17,643] Trial 9 finished with value: 0.9147242903709412 and parameters: {}. Best is trial 3 with value: 0.7136643528938293.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "\n",
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri('http://localhost:8080')\n",
    "mlflow.autolog()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def eval_step_with_mlflowlogging(model,test_dataloader):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_preds = []\n",
    "        total_labels = []\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(total_labels, total_preds)\n",
    "    precision = precision_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    recall = recall_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted', labels=np.unique(total_preds))\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def train_with_mlflowlogging(model, loss_func, optimizer, train_dataloader, test_dataloader, n_epochs):\n",
    "    \n",
    "    train_loss = []\n",
    "    \n",
    "    test_loss = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        tr_loss = train_step(model, loss_func, optimizer, train_dataloader)\n",
    "        train_loss.append(tr_loss)\n",
    "    \n",
    "        ts_loss = test_step(model, loss_func, test_dataloader)\n",
    "        test_loss.append(ts_loss)    \n",
    "\n",
    "        accuracy, precision, recall, f1 = eval_step_with_mlflowlogging(model, test_dataloader)\n",
    "        \n",
    "        mlflow.log_metric(\"loss\", tr_loss)#, step = epoch)\n",
    "        mlflow.log_metric(\"val_loss\", ts_loss)#, step = epoch)\n",
    "\n",
    "        mlflow.log_metric(\"loss\", tr_loss)#, step = epoch)\n",
    "        mlflow.log_metric(\"val_loss\", ts_loss)#, step = epoch)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)#, step = epoch)\n",
    "        mlflow.log_metric(\"precision\", precision)#, step = epoch)\n",
    "        mlflow.log_metric(\"recall\", recall)#, step = epoch)\n",
    "        mlflow.log_metric(\"f1\", f1, step = epoch)#)   \n",
    "\n",
    "    return train_loss, test_loss\n",
    "\n",
    "# Example of starting an MLflow run and integrating Optuna for hyperparameter tuning\n",
    "with mlflow.start_run():\n",
    "    def objective(trial):\n",
    "        # Use trial.suggest_* methods to suggest hyperparameters\n",
    "        # batch_size = 10,50,len(training_data)\n",
    "        batch_size = len(training_data)\n",
    "        \n",
    "        # hidden dim = 25,50,100\n",
    "        hidden_dim =100\n",
    "\n",
    "        # GB, SGD batch 1, SGD minibatch 10 e 50\n",
    "        # lr = 0.5, 1, 10\n",
    "        lr = 0.5\n",
    "\n",
    "        # Log params\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "\n",
    "        # Define your model here\n",
    "        train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "        model = NeuralNetwork(input_size = X_train.shape[1], hidden_dim= hidden_dim, output_size=10).to(device)\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        train_loss, test_loss = train_with_mlflowlogging(\n",
    "            model, \n",
    "            loss_func, \n",
    "            optimizer, \n",
    "            train_dataloader, \n",
    "            test_dataloader, \n",
    "            n_epochs= 20)\n",
    "\n",
    "        # mlflow.log_metric(\"loss\", train_loss[-1])\n",
    "        # mlflow.log_metric(\"val_loss\", test_loss[-1])\n",
    "\n",
    "        return  test_loss[-1]  # Return a value to minimize (e.g., negative accuracy)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name = \"testing_mlflow_optuna_2\", load_if_exists = True)\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # Log the best parameters and other relevant information\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_loss\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
